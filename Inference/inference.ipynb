{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference\n",
    "This notebook provides inference for semantic segmentation and instance segmentation respectively.\n",
    " \n",
    "Use the model to predict the results on the test set and calculate the accuracy (iou, fp, fn, tp, tf, ap), and save the visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import csv\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "from inference_sdk import InferenceHTTPClient, InferenceConfiguration\n",
    "\n",
    "import shapely.geometry as geom\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.errors import TopologicalError\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "from roboflow import Roboflow\n",
    "\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from tensorflow.keras.metrics import Precision, Recall, IoU\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import base64\n",
    "import io\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### semantic segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test on single image, semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test semantic segmentation on a single image\n",
    "# 只能这样设置，原因未知\n",
    "\n",
    "\n",
    "# 2048 tile的semantic segmentation\n",
    "# rf = Roboflow(api_key=\"uZgVV5Mu30Veqelqd61T\")\n",
    "# project = rf.workspace().project(\"ss-favela-2048to1024-only-mask\") # input model id\n",
    "# model = project.version(\"1\").model # input model version\n",
    "\n",
    "# image_path = 'demo/original_2048_RGB.jpg'\n",
    "\n",
    "# # print(model.predict(image_path).json())\n",
    "# prediction = model.predict(image_path)\n",
    "\n",
    "# print(prediction.json())\n",
    "# model.predict(image_path).save(\"demo/prediction_2048.jpg\")\n",
    "\n",
    "\n",
    "#  400 tile的semantic segmentation\n",
    "rf = Roboflow(api_key=\"ukRLimOMKqvRJtEskQFC\")\n",
    "project = rf.workspace().project(\"semantic-segmentation-satellite\") # input model id\n",
    "model = project.version(\"1\").model # input model version\n",
    "\n",
    "image_path = 'demo/original.jpg'\n",
    "\n",
    "prediction = model.predict(image_path)\n",
    "\n",
    "print(prediction.json())\n",
    "model.predict(image_path).save(\"demo/prediction_400.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import base64\n",
    "from PIL import Image, ImageDraw\n",
    "import io\n",
    "from roboflow import Roboflow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize Roboflow and model\n",
    "rf = Roboflow(api_key=\"ukRLimOMKqvRJtEskQFC\")\n",
    "project = rf.workspace().project(\"semantic-segmentation-satellite\")\n",
    "model = project.version(\"1\").model\n",
    "\n",
    "# Input image path\n",
    "image_path = 'SS_Rio_tile1024_stride0.v1i.coco-segmentation/test/000000005993_png.rf.3459be7a8ba7c2dc7f73edc5d5ea9a44.jpg'\n",
    "\n",
    "# Perform prediction\n",
    "prediction = model.predict(image_path)\n",
    "prediction_data = prediction.json()\n",
    "\n",
    "# Decode the predicted segmentation mask\n",
    "segmentation_mask_b64 = prediction_data['predictions'][0]['segmentation_mask']\n",
    "decoded_mask = base64.b64decode(segmentation_mask_b64)\n",
    "pred_mask = np.array(Image.open(io.BytesIO(decoded_mask)))\n",
    "\n",
    "# Load the original image\n",
    "original_image = cv2.imread(image_path)\n",
    "original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)  # Convert to RGB for visualization\n",
    "\n",
    "# Print sizes of the mask and the original image\n",
    "print(f\"Original image size: {original_image.shape[:2]} (height, width)\")\n",
    "print(f\"Predicted mask size: {pred_mask.shape[:2]} (height, width)\")\n",
    "\n",
    "# Resize the predicted mask to match the original image dimensions\n",
    "if pred_mask.shape[:2] != original_image.shape[:2]:\n",
    "    print(f\"Resizing predicted mask from {pred_mask.shape[:2]} to {original_image.shape[:2]}\")\n",
    "    pred_mask_resized = cv2.resize(pred_mask, (original_image.shape[1], original_image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "else:\n",
    "    pred_mask_resized = pred_mask\n",
    "\n",
    "# Convert the predicted mask to an overlay\n",
    "overlay = np.zeros_like(original_image, dtype=np.uint8)\n",
    "overlay[pred_mask_resized > 0] = [255, 0, 0]  # Red color for mask\n",
    "\n",
    "# Blend the original image and the mask overlay\n",
    "blended_image = cv2.addWeighted(original_image, 0.7, overlay, 0.3, 0)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(blended_image)\n",
    "plt.axis('off')\n",
    "plt.title('Original Image with Predicted Mask Overlay')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont, ImageDraw\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import base64\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from roboflow import Roboflow\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "def add_labels(image, label, iou=None, font_size=30):\n",
    "    \"\"\"Add a label and optional IoU score at the top of the image.\"\"\"\n",
    "    # Create a new image with space for the label above the original image\n",
    "    width, height = image.size\n",
    "    label_height = font_size + 20  # Adjusted space for the label\n",
    "    new_image = Image.new(\"RGBA\", (width, height + label_height), (0, 0, 0, 255))  # Black background for the label\n",
    "\n",
    "    # Paste the original image below the label space\n",
    "    new_image.paste(image, (0, label_height))\n",
    "\n",
    "    # Draw the label in the new image\n",
    "    draw = ImageDraw.Draw(new_image)\n",
    "\n",
    "    # Use a TTF font with the specified size\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"calibri.ttf\", font_size)  # Use Times New Roman or any other font\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()  # Fallback to default font if TTF font is unavailable\n",
    "\n",
    "    # Create the text\n",
    "    text = label\n",
    "    if iou is not None:\n",
    "        text += f\" (IoU: {iou:.4f})\"\n",
    "\n",
    "    # Calculate text position (centered at the top)\n",
    "    bbox = draw.textbbox((0, 0), text, font=font)  # Get text bounding box\n",
    "    text_width = bbox[2] - bbox[0]  # Text width\n",
    "    text_height = bbox[3] - bbox[1]  # Text height\n",
    "    text_position = ((width - text_width) // 2, (label_height - text_height) // 2)  # Centered within label height\n",
    "\n",
    "    # Draw the text\n",
    "    draw.text(text_position, text, fill=\"white\", font=font)\n",
    "\n",
    "    return new_image\n",
    "\n",
    "def combine_images_with_labels(images, labels, iou=None, border_width=20, font_size=30, outer_margin=20):\n",
    "    \"\"\"\n",
    "    Combine multiple images with labels and black borders between them.\n",
    "    \n",
    "    Parameters:\n",
    "        images (list): List of PIL.Image objects to combine.\n",
    "        labels (list): List of labels corresponding to the images.\n",
    "        iou (float, optional): IoU score for the last image.\n",
    "        border_width (int): Width of the black border between images.\n",
    "        font_size (int): Font size for the labels.\n",
    "    \n",
    "    Returns:\n",
    "        PIL.Image: A new image combining all input images with labels and black borders.\n",
    "    \"\"\"\n",
    "    assert len(images) == len(labels), \"Images and labels must have the same length.\"\n",
    "\n",
    "    labeled_images = []\n",
    "    for i, img in enumerate(images):\n",
    "        # Add IoU only to the last image\n",
    "        iou_value = iou if i == len(images) - 1 else None\n",
    "        labeled_image = add_labels(img, labels[i], iou_value, font_size=font_size)\n",
    "        labeled_images.append(labeled_image)\n",
    "\n",
    "    # Calculate total width and maximum height\n",
    "    widths = [img.width for img in labeled_images]\n",
    "    total_width = sum(widths) + border_width * (len(labeled_images) - 1)\n",
    "    max_height = max(img.height for img in labeled_images)\n",
    "\n",
    "    # Create a new image with black background\n",
    "    combined_image = Image.new(\"RGBA\", (total_width, max_height), (0, 0, 0, 255))\n",
    "\n",
    "    # Paste images with black borders\n",
    "    x_offset = 0\n",
    "    for idx, img in enumerate(labeled_images):\n",
    "        combined_image.paste(img, (x_offset, 0))\n",
    "        x_offset += img.width + border_width\n",
    "    \n",
    "    # Add outer margin (black padding)\n",
    "    final_image_with_margin = Image.new(\n",
    "        \"RGBA\",\n",
    "        (combined_image.width + 2 * outer_margin, combined_image.height + 2 * outer_margin),\n",
    "        (0, 0, 0, 255),\n",
    "    )\n",
    "    final_image_with_margin.paste(combined_image, (outer_margin, outer_margin))\n",
    "\n",
    "    return final_image_with_margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IOU calculation test using tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 创建一个MeanIoU实例\n",
    "m = tf.keras.metrics.MeanIoU(num_classes=2)\n",
    "\n",
    "# 更新状态\n",
    "m.update_state([0, 0, 1, 1], [0, 1, 0, 1], sample_weight=[0.3, 0.3, 0.3, 0.1])\n",
    "\n",
    "# 计算结果\n",
    "result = m.result().numpy()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "IOU results saved to SS_Rio_tile1024_stride0.v1i.coco-segmentation/valid\\segmentation_results_fp_fn\\iou_results_tf.csv\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "得到每张图片的mean IOU\n",
    "以下代码仅供数值比较，这样计算是有问题的\n",
    "最后mean IOU是混淆矩阵累加而不是mean IOU取均值\n",
    "'''\n",
    "\n",
    "# Initialize Roboflow and model\n",
    "rf = Roboflow(api_key=\"uZgVV5Mu30Veqelqd61T\")\n",
    "project = rf.workspace().project(\"ss_rio_tile1024_stride0\") # input model id\n",
    "model = project.version(\"1\").model # input model version\n",
    "\n",
    "# COCO数据集路径\n",
    "image_dir = 'SS_Rio_tile1024_stride0.v1i.coco-segmentation/valid'\n",
    "coco_json_path = os.path.join(image_dir, \"_annotations.coco.json\")\n",
    "\n",
    "# 加载COCO数据集\n",
    "with open(coco_json_path) as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "image_ids = [image['id'] for image in coco_data['images']]  # 获取所有图片的ID\n",
    "\n",
    "# 初始化 MeanIoU 度量\n",
    "num_classes = 2  # 假设有2个类别（背景和目标）\n",
    "mean_iou_metric = MeanIoU(num_classes=num_classes)\n",
    "iou_metric = IoU(num_classes=num_classes, target_class_ids=[1]) \n",
    "\n",
    "\n",
    "# 初始化COCO类，用于获取真实标签\n",
    "coco = COCO(coco_json_path)\n",
    "\n",
    "output_dir = os.path.join(image_dir, \"segmentation_results_fp_fn\")\n",
    "iou_csv_path = os.path.join(output_dir, \"iou_results_tf.csv\")\n",
    "with open(iou_csv_path, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"Image Name\", \"mIoU\", \"IOU for slum(id=1)\",\"tn\", \"fp\", \"fn\", \"tp\"])  # Header for CSV\n",
    "    \n",
    "    # 遍历所有图片，获取 COCO 数据集的标签以及模型的预测结果\n",
    "    for image_id in image_ids:\n",
    "        # 获取真实标签\n",
    "        anns = coco.loadAnns(coco.getAnnIds(imgIds=image_id))  # 获取与图片ID对应的所有标注\n",
    "        image_info = coco.loadImgs(image_id)[0]\n",
    "        image_file_name = image_info['file_name']\n",
    "        image_path = os.path.join(image_dir, image_info['file_name'])\n",
    "\n",
    "        # 读取图像并进行预处理\n",
    "        image = plt.imread(image_path)  # 使用matplotlib读取图像\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        # 获取图像的实际标签 (ground truth mask)\n",
    "        true_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        for ann in anns:\n",
    "            mask = coco.annToMask(ann)\n",
    "            true_mask[mask == 1] = 1  # 用真实标签填充\n",
    "\n",
    "        # 通过模型进行预测（假设您有一个训练好的模型）\n",
    "        result = model.predict(image_path)\n",
    "        prediction = result.json()\n",
    "        segmentation_mask_b64 = prediction['predictions'][0]['segmentation_mask']\n",
    "        mask_data = base64.b64decode(segmentation_mask_b64)\n",
    "        mask_image = Image.open(io.BytesIO(mask_data)).convert(\"L\")  # 转为灰度图\n",
    "        predicted_mask = np.array(mask_image)  # 转换为NumPy数组\n",
    "        predicted_mask_resized = cv2.resize(predicted_mask, (true_mask.shape[1], true_mask.shape[0]))\n",
    "\n",
    "        conf_matrix = confusion_matrix(true_mask.flatten(), predicted_mask_resized.flatten(), labels=[0, 1])\n",
    "        tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "        # Compute IoU\n",
    "        mean_iou_metric.update_state(true_mask, predicted_mask_resized)\n",
    "        iou_metric.update_state(true_mask, predicted_mask_resized)\n",
    "\n",
    "        image_iou = mean_iou_metric.result().numpy()\n",
    "        iou = iou_metric.result().numpy()\n",
    "\n",
    "        csv_writer.writerow([image_file_name, image_iou, iou,tn, fp, fn, tp])  # Write the image name and its IoU\n",
    "        mean_iou_metric.reset_state()  # 知道逻辑之后不应该每张图片单独计\n",
    "        iou_metric.reset_state()  # 知道逻辑之后不应该每张图片单独计算算\n",
    "\n",
    "    # # 计算 Mean IoU\n",
    "    # mean_iou_value = mean_iou_metric.result().numpy()\n",
    "    # print(f\"Mean IoU: {mean_iou_value}\")\n",
    "print(f\"IOU results saved to {iou_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = tf.keras.metrics.FalsePositives()\n",
    "false_negatives = tf.keras.metrics.FalseNegatives()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_mask.shape)\n",
    "print(np.unique(true_mask))\n",
    "\n",
    "print(predicted_mask_resized.shape)\n",
    "print(np.unique(predicted_mask_resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "true_mask_flat = true_mask.flatten()\n",
    "predicted_mask_flat = predicted_mask_resized.flatten()\n",
    "\n",
    "# 计算混淆矩阵\n",
    "conf_matrix = confusion_matrix(true_mask_flat, predicted_mask_flat, labels=[0, 1])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "对一组图片\n",
    "'''\n",
    "\n",
    "# 初始化 MeanIoU 度量\n",
    "num_classes = 2  # 假设有2个类别（背景和目标）\n",
    "mean_iou_metric = MeanIoU(num_classes=num_classes)\n",
    "iou = IoU(num_classes=num_classes, target_class_ids=[1]) \n",
    "\n",
    "# 初始化COCO类，用于获取真实标签\n",
    "coco = COCO(coco_json_path)\n",
    "\n",
    "# output_dir = os.path.join(image_dir, \"segmentation_results_fp_fn\")\n",
    "# iou_csv_path = os.path.join(output_dir, \"iou_results_tf.csv\")\n",
    "# with open(iou_csv_path, mode='w', newline='') as csv_file:\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "#     csv_writer.writerow([\"Image Name\", \"IoU\"])  # Header for CSV\n",
    "    \n",
    "# 遍历所有图片，获取 COCO 数据集的标签以及模型的预测结果\n",
    "for image_id in image_ids:\n",
    "    # 获取真实标签\n",
    "    anns = coco.loadAnns(coco.getAnnIds(imgIds=image_id))  # 获取与图片ID对应的所有标注\n",
    "    image_info = coco.loadImgs(image_id)[0]\n",
    "    image_file_name = image_info['file_name']\n",
    "    image_path = os.path.join(image_dir, image_info['file_name'])\n",
    "\n",
    "    # 读取图像并进行预处理\n",
    "    image = plt.imread(image_path)  # 使用matplotlib读取图像\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # 获取图像的实际标签 (ground truth mask)\n",
    "    true_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    for ann in anns:\n",
    "        mask = coco.annToMask(ann)\n",
    "        true_mask[mask == 1] = 1  # 用真实标签填充\n",
    "\n",
    "    # 通过模型进行预测（假设您有一个训练好的模型）\n",
    "    result = model.predict(image_path)\n",
    "    prediction = result.json()\n",
    "    segmentation_mask_b64 = prediction['predictions'][0]['segmentation_mask']\n",
    "    mask_data = base64.b64decode(segmentation_mask_b64)\n",
    "    mask_image = Image.open(io.BytesIO(mask_data)).convert(\"L\")  # 转为灰度图\n",
    "    predicted_mask = np.array(mask_image)  # 转换为NumPy数组\n",
    "    predicted_mask_resized = cv2.resize(predicted_mask, (true_mask.shape[1], true_mask.shape[0]))\n",
    "\n",
    "    # Compute IoU\n",
    "    mean_iou_metric.update_state(true_mask, predicted_mask_resized)\n",
    "    iou.update_state(true_mask, predicted_mask_resized)\n",
    "    # image_iou = mean_iou_metric.result().numpy()\n",
    "    # csv_writer.writerow([image_file_name, image_iou])  # Write the image name and its IoU\n",
    "    # mean_iou_metric.reset_state()\n",
    "\n",
    "# # 计算 Mean IoU\n",
    "mean_iou_value = mean_iou_metric.result().numpy()\n",
    "target_cate_iou = iou.result().numpy()\n",
    "print(f\"Mean IoU: {mean_iou_value} \\n target_cate_iou:{target_cate_iou}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOU:\n",
    "\n",
    "tf: 0.7343394756317139\n",
    "- 但是对每张图片处理取平均是0.69？？ - solved 混淆矩阵累加\n",
    "- 之前的方法算出来是0.56左右 - solved 只算了一类\n",
    "\n",
    "\n",
    "算一类 -> 算多类 -> 混淆矩阵累加\n",
    "roboflow: 0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_iou_metric.reset_state()\n",
    "mean_iou_metric.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 1  # 选择一个单一的图片 ID\n",
    "\n",
    "with open(coco_json_path) as f:\n",
    "    coco_data = json.load(f)\n",
    "img_info = next((img for img in coco_data['images'] if img['id'] == image_id), None)\n",
    "\n",
    "# 获取真实标签\n",
    "anns = coco.loadAnns(coco.getAnnIds(imgIds=image_id))  # 获取与图片ID对应的所有标注\n",
    "image_info = coco.loadImgs(image_id)[0]\n",
    "image_path = os.path.join(image_dir, image_info['file_name'])\n",
    "\n",
    "# 读取图像并进行预处理\n",
    "image = plt.imread(image_path)  # 使用matplotlib读取图像\n",
    "height, width, _ = image.shape\n",
    "\n",
    "# 获取图像的实际标签 (ground truth mask)\n",
    "true_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "for ann in anns:\n",
    "    mask = coco.annToMask(ann)\n",
    "    true_mask[mask == 1] = 1  # 用真实标签填充\n",
    "\n",
    "# 通过模型进行预测（假设您有一个训练好的模型）\n",
    "result = model.predict(image_path)\n",
    "prediction = result.json()\n",
    "segmentation_mask_b64 = prediction['predictions'][0]['segmentation_mask']\n",
    "mask_data = base64.b64decode(segmentation_mask_b64)\n",
    "mask_image = Image.open(io.BytesIO(mask_data)).convert(\"L\")  # 转为灰度图\n",
    "predicted_mask = np.array(mask_image)  # 转换为NumPy数组\n",
    "predicted_mask_resized = cv2.resize(predicted_mask, (true_mask.shape[1], true_mask.shape[0]))  # 缩放预测的mask以匹配实际图像的大小\n",
    "\n",
    "# 计算 IoU\n",
    "mean_iou_metric.reset_state()\n",
    "mean_iou_metric.update_state(true_mask, predicted_mask_resized)\n",
    "mean_iou_metric.result()\n",
    "\n",
    "# 计算 Mean IoU\n",
    "mean_iou_value = mean_iou_metric.result().numpy()\n",
    "print(f\"Mean IoU for image {image_id},{img_info['file_name']}: {mean_iou_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou_for_each_class(gt_mask, pred_mask, num_classes):\n",
    "    iou_list = []\n",
    "    for class_id in range(num_classes):\n",
    "        gt_class_binary = (gt_mask == class_id).astype(np.uint8)\n",
    "        pred_class_binary = (pred_mask == class_id).astype(np.uint8)\n",
    "\n",
    "        intersection = np.logical_and(gt_class_binary, pred_class_binary).sum()\n",
    "        union = np.logical_or(gt_class_binary, pred_class_binary).sum()\n",
    "\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "        iou_list.append(iou)\n",
    "    return np.mean(iou_list)  # mIoU is the average of individual class IoUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for visulization only (improved) \n",
    "\n",
    "\n",
    "\n",
    "# # Initialize Roboflow and model\n",
    "# # rf = Roboflow(api_key=\"uZgVV5Mu30Veqelqd61T\")\n",
    "# # project = rf.workspace().project(\"ss-tijuca2019_tile400_stride0\")\n",
    "# # model = project.version(\"1\").model  # Specify version\n",
    "\n",
    "# # # Input and output directories\n",
    "# # image_dir = 'SS-Tijuca2019_tile400_stride0.v1i.coco-segmentation/test'\n",
    "\n",
    "\n",
    "# # Initialize Roboflow and model\n",
    "# rf = Roboflow(api_key=\"uZgVV5Mu30Veqelqd61T\")\n",
    "# project = rf.workspace().project(\"ss_rio_tile1024_stride0\") # input model id\n",
    "# model = project.version(\"1\").model # input model version\n",
    "\n",
    "# # Input and output directories\n",
    "# image_dir = 'SS_Rio_tile1024_stride0.v1i.coco-segmentation/test'\n",
    "\n",
    "\n",
    "# coco_json_path = os.path.join(image_dir, \"_annotations.coco.json\")\n",
    "# output_dir = os.path.join(image_dir, \"segmentation_results_fp_fn_portfolio\")\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Initialize CSV for IoU results\n",
    "# iou_csv_path = os.path.join(output_dir, \"iou_results.csv\")\n",
    "# with open(iou_csv_path, mode='w', newline='') as csv_file:\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "#     csv_writer.writerow([\"Image Name\", \"IoU\", \"AP50\", \"AP75\", \"mAP\", \"fn_count\", \"fp_count\", \"tp_count\",\"total_pixels\"])\n",
    "\n",
    "#     with open(coco_json_path) as f:\n",
    "#         coco_data = json.load(f)\n",
    "\n",
    "#     image_ids = [image['id'] for image in coco_data['images']]\n",
    "#     threshold_list = np.linspace(0.5, 0.95, 10)  # IoU thresholds for mAP\n",
    "    \n",
    "#     for image_id in image_ids:\n",
    "#         if image_id != -1: \n",
    "#             image_info = next(img for img in coco_data['images'] if img['id'] == image_id)\n",
    "#             image_file_name = image_info['file_name']\n",
    "#             img_path = os.path.join(image_dir, image_file_name)\n",
    "\n",
    "#             # Load ground truth annotations\n",
    "#             gt_annotations = [anno for anno in coco_data['annotations'] if anno['image_id'] == image_id]\n",
    "#             im = cv2.imread(img_path)\n",
    "#             gt_mask = np.zeros((im.shape[0], im.shape[1]), dtype=np.uint8)\n",
    "\n",
    "#             for annotation in gt_annotations:\n",
    "#                 segmentation = annotation['segmentation'][0]\n",
    "#                 points = [(segmentation[i], segmentation[i + 1]) for i in range(0, len(segmentation), 2)]\n",
    "#                 cv2.fillPoly(gt_mask, [np.array(points, dtype=np.int32)], 1)\n",
    "\n",
    "#             # Perform inference\n",
    "#             result = model.predict(img_path)\n",
    "#             prediction = result.json()\n",
    "\n",
    "#             if not prediction['predictions']:\n",
    "#                 print(f\"No predictions for {image_file_name}. Skipping.\")\n",
    "#                 csv_writer.writerow([image_file_name, \"No predictions\"])\n",
    "#                 continue\n",
    "\n",
    "#             # Decode prediction mask\n",
    "#             segmentation_mask_b64 = prediction['predictions'][0]['segmentation_mask']\n",
    "#             decoded_mask = base64.b64decode(segmentation_mask_b64)\n",
    "#             pred_mask = np.array(Image.open(io.BytesIO(decoded_mask)))\n",
    "\n",
    "#             # Resize pred_mask to match gt_mask dimensions\n",
    "#             pred_mask_resized = cv2.resize(pred_mask, (gt_mask.shape[1], gt_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "#             pred_mask_resized = (pred_mask_resized > 0).astype(np.uint8) \n",
    "\n",
    "\n",
    "\n",
    "#             # Flatten masks for precision-recall computation\n",
    "#             gt_flat = (gt_mask.flatten() > 0).astype(np.uint8)  # Ensure ground truth values are {0, 1}\n",
    "#             pred_flat = pred_mask_resized.flatten() / 255.0\n",
    "\n",
    "#             # Calculate Precision-Recall curve\n",
    "#             precision, recall, _ = precision_recall_curve(gt_flat, pred_flat)\n",
    "#             ap50 = average_precision_score(gt_flat, pred_flat)  # AP50 calculation\n",
    "\n",
    "#             # Calculate AP at each IoU threshold\n",
    "#             ap_values = []\n",
    "#             for threshold in threshold_list:\n",
    "#                 pred_binary = (pred_flat >= threshold * 255).astype(np.uint8)  # Binarize predictions\n",
    "#                 precision, recall, _ = precision_recall_curve(gt_flat, pred_binary)\n",
    "#                 ap = average_precision_score(gt_flat, pred_binary)\n",
    "#                 ap_values.append(ap)\n",
    "\n",
    "#             # Extract AP50 and AP75\n",
    "#             ap50 = ap_values[0]  # First value corresponds to IoU=0.5\n",
    "#             ap75 = ap_values[5]  # Sixth value corresponds to IoU=0.75\n",
    "#             mAP = np.mean(ap_values)  # Mean of all AP values\n",
    "\n",
    "            \n",
    "#             # Construct confusion matrix for binary segmentation\n",
    "#             conf_matrix = np.zeros((2, 2), dtype=np.int32)\n",
    "#             for gt, pred in zip(gt_flat, (pred_flat >= 0.5).astype(np.uint8)):\n",
    "#                 conf_matrix[gt, pred] += 1\n",
    "\n",
    "#             # Error mask\n",
    "#             error_mask = cv2.bitwise_and(gt_mask, cv2.bitwise_not(pred_mask_resized))\n",
    "#             fn_mask = cv2.bitwise_and(gt_mask, cv2.bitwise_not(pred_mask_resized))          # False Negative (FN): Ground Truth is 1, Prediction is 0\n",
    "#             fp_mask = cv2.bitwise_and(pred_mask_resized, cv2.bitwise_not(gt_mask))        # False Positive (FP): Prediction is 1, Ground Truth is 0\n",
    "#             tp_mask = cv2.bitwise_and(gt_mask, pred_mask_resized)\n",
    "\n",
    "#             # IoU calculation\n",
    "#             # gt_binary = (gt_mask > 0).astype(np.uint8)\n",
    "#             # pred_binary = (pred_mask_resized > 0).astype(np.uint8)\n",
    "\n",
    "#             # intersection = np.logical_and(gt_binary, pred_binary).sum()\n",
    "#             # union = np.logical_or(gt_binary, pred_binary).sum()\n",
    "#             # iou = intersection / union if union > 0 else 0\n",
    "\n",
    "#             iou = compute_iou_for_each_class(gt_mask,pred_mask_resized,2)\n",
    "\n",
    "#             # Calculate FN, FP, and TP counts\n",
    "#             fn_count = np.sum(fn_mask)\n",
    "#             fp_count = np.sum(fp_mask)\n",
    "#             tp_count = np.sum(gt_mask & pred_mask_resized)\n",
    "#             total_pixels = gt_mask.size\n",
    "\n",
    "#             # Write to CSV\n",
    "#             csv_writer.writerow([image_file_name, iou, ap50, ap75, mAP, fn_count, fp_count, tp_count, total_pixels])\n",
    "\n",
    "#             # Visualization: overlay ground truth and prediction on the original image\n",
    "#             original_image = Image.open(img_path).convert(\"RGBA\")\n",
    "\n",
    "#             # Ground truth overlay\n",
    "#             overlay_gt = Image.new(\"RGBA\", original_image.size, (255, 255, 255, 0))\n",
    "#             draw_gt = ImageDraw.Draw(overlay_gt)\n",
    "#             for annotation in gt_annotations:\n",
    "#                 segmentation = annotation['segmentation'][0]\n",
    "#                 points = [(segmentation[i], segmentation[i + 1]) for i in range(0, len(segmentation), 2)]\n",
    "#                 draw_gt.polygon(points, fill=(255, 255, 255, 100))  # Semi-transparent red for ground truth\n",
    "#             combined_gt = Image.alpha_composite(original_image, overlay_gt)\n",
    "\n",
    "#             # Prediction overlay\n",
    "#             # Create a transparent RGBA image for the prediction overlay\n",
    "#             overlay_pred = Image.new(\"RGBA\", original_image.size, (255, 255, 255, 0))\n",
    "#             pred_mask_grayscale = Image.fromarray((pred_mask_resized * 255).astype(np.uint8), mode=\"L\")  # 0 for background, 255 for prediction\n",
    "#             pred_mask_colored = Image.new(\"RGBA\", pred_mask_grayscale.size, (0, 0, 255, 30))  # Blue with transparency\n",
    "#             overlay_pred = Image.composite(pred_mask_colored, overlay_pred, pred_mask_grayscale)\n",
    "#             combined_pred = Image.alpha_composite(original_image, overlay_pred)\n",
    "\n",
    "#             # # Create a PIL image with black background and white error regions\n",
    "#             error_image = Image.fromarray(\n",
    "#                 np.where(\n",
    "#                     error_mask[..., None] > 0,  # Condition for error pixels\n",
    "#                     [255, 255, 255, 255],         # White for error pixels\n",
    "#                     [0, 0, 0, 255]                # Black for non-error pixels\n",
    "#                 ).astype(np.uint8)\n",
    "#             )\n",
    "\n",
    "#             tp_image = Image.fromarray(\n",
    "#                 np.where(\n",
    "#                     tp_mask[..., None] > 0,  # Condition for error pixels\n",
    "#                     [255, 255, 255, 255],         # White for error pixels\n",
    "#                     [0, 0, 0, 255]                # Black for non-error pixels\n",
    "#                 ).astype(np.uint8)\n",
    "#             )\n",
    "\n",
    "\n",
    "#             # Error overlay (FN in red, FP in blue)\n",
    "#             overlay_error = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 255))\n",
    "#             fn_pil = Image.fromarray((fn_mask > 0).astype(np.uint8) * 255).convert(\"L\")\n",
    "#             fp_pil = Image.fromarray((fp_mask > 0).astype(np.uint8) * 255).convert(\"L\")\n",
    "#             tp_pil = Image.fromarray((tp_mask > 0).astype(np.uint8) * 255).convert(\"L\")\n",
    "#             error_draw = ImageDraw.Draw(overlay_error)\n",
    "#             error_draw.bitmap((0, 0), fn_pil, fill=(255, 255, 0, 100))  # Red for False Negative, (255, 0, 0, 100)   (50, 50, 50, 255)\n",
    "#             error_draw.bitmap((0, 0), fp_pil, fill=(0, 255, 255, 100))  # Blue for False Positive,(0, 0, 255, 100)   (200, 200, 200, 255)\n",
    "#             error_draw.bitmap((0, 0), tp_pil, fill=(0, 0, 0, 255)) \n",
    "#             combined_error = overlay_error\n",
    "\n",
    "#             # Plot results\n",
    "#             fig, axs = plt.subplots(1, 5, figsize=(20, 10))\n",
    "#             axs[0].imshow(original_image)\n",
    "#             axs[0].axis('off')\n",
    "#             axs[0].set_title('Original Image')\n",
    "\n",
    "#             axs[1].imshow(combined_gt)\n",
    "#             axs[1].axis('off')\n",
    "#             axs[1].set_title('Ground Truth Overlay')\n",
    "\n",
    "#             axs[2].imshow(combined_pred)\n",
    "#             axs[2].axis('off')\n",
    "#             axs[2].set_title('Prediction Overlay')\n",
    "\n",
    "#             # tp_mask\n",
    "#             axs[3].imshow(np.array(tp_mask)) \n",
    "#             axs[3].axis('off')\n",
    "#             axs[3].set_title(f'True Positive Overlay')\n",
    "\n",
    "#             axs[4].imshow(np.array(combined_error))  # Error visualization (FN & FP) \n",
    "#             axs[4].axis('off')\n",
    "#             axs[4].set_title(\"Error (IoU: {iou:.4f})\")\n",
    "\n",
    "#             # save img\n",
    "#             output_path = os.path.join(output_dir, f\"{image_file_name}_result.png\")\n",
    "\n",
    "#             images = [original_image, combined_gt, combined_pred, tp_image, combined_error]\n",
    "#             labels = [\"Original Image\", \"Ground Truth\", \"Prediction\",\"True Positive Overlay\", \"Error Map\"]\n",
    "#             final_image = combine_images_with_labels(images, labels, iou=iou, border_width=30, font_size=30,outer_margin=30)\n",
    "#             final_image.save(output_path)\n",
    "            \n",
    "#             # plt.savefig(output_path, bbox_inches='tight', pad_inches=0.1)\n",
    "#             # plt.close(fig)\n",
    "#             plt.show()\n",
    "\n",
    "#             print(f\"Image: {image_file_name} | IoU: {iou:.4f} | AP50: {ap50:.4f} | AP75: {ap75:.4f} | mAP: {mAP:.4f} | mAP: {mAP:.4f} \")\n",
    "\n",
    "# print(f\"IoU results saved to {iou_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow project...\n",
      "Image: 000000004768_png.rf.0e5109576c9b35e2f8179ae3f50a7efd.jpg | IoU: 0.6881 | AP50: 0.1096 | AP75: 0.1096 | mAP: 0.1096 | mAP: 0.1096 | fn_ratio: 0.0346 | fp_ratio: 0.0505 |  tp_ratio: 0.0750\n",
      "Image: 000000003270_png.rf.1cd5cf5aefd4008f661f1b4d4af28c15.jpg | IoU: 0.5846 | AP50: 0.6322 | AP75: 0.6322 | mAP: 0.6322 | mAP: 0.6322 | fn_ratio: 0.2131 | fp_ratio: 0.0470 |  tp_ratio: 0.4191\n",
      "Image: 000000003257_png.rf.04268d1dedf15db0fc3ff73bcf7ffb42.jpg | IoU: 0.4603 | AP50: 0.1844 | AP75: 0.1844 | mAP: 0.1844 | mAP: 0.1844 | fn_ratio: 0.0349 | fp_ratio: 0.2968 |  tp_ratio: 0.1495\n",
      "Image: 000000005520_png.rf.0c1fcc9956dcdf55591ae5e3ca926ac3.jpg | IoU: 0.7694 | AP50: 0.0963 | AP75: 0.0963 | mAP: 0.0963 | mAP: 0.0963 | fn_ratio: 0.0326 | fp_ratio: 0.0123 |  tp_ratio: 0.0637\n",
      "Image: 000000005558_png.rf.10669832edfb0b67fa5937b3fe5b20d2.jpg | IoU: 0.7685 | AP50: 0.1692 | AP75: 0.1692 | mAP: 0.1692 | mAP: 0.1692 | fn_ratio: 0.0616 | fp_ratio: 0.0062 |  tp_ratio: 0.1075\n",
      "Image: 000000008470_png.rf.11ef5d8104e3d526ead079dcb2407257.jpg | IoU: 0.7534 | AP50: 0.1712 | AP75: 0.1712 | mAP: 0.1712 | mAP: 0.1712 | fn_ratio: 0.0529 | fp_ratio: 0.0269 |  tp_ratio: 0.1183\n",
      "Image: 000000003783_png.rf.25ad84682e53a12e45b68bbd930fcb33.jpg | IoU: 0.8901 | AP50: 0.3046 | AP75: 0.3046 | mAP: 0.3046 | mAP: 0.3046 | fn_ratio: 0.0407 | fp_ratio: 0.0075 |  tp_ratio: 0.2639\n",
      "Image: 000000005995_png.rf.2e32527d5f2c92b9aceb3b371a78e1ff.jpg | IoU: 0.6426 | AP50: 0.0751 | AP75: 0.0751 | mAP: 0.0751 | mAP: 0.0751 | fn_ratio: 0.0493 | fp_ratio: 0.0014 |  tp_ratio: 0.0258\n",
      "Image: 000000006011_png.rf.36ae97f7606585fdb48a08c4c9c0eeb7.jpg | IoU: 0.7948 | AP50: 0.1503 | AP75: 0.1503 | mAP: 0.1503 | mAP: 0.1503 | fn_ratio: 0.0446 | fp_ratio: 0.0116 |  tp_ratio: 0.1057\n",
      "Image: 000000003256_png.rf.3cf2560d4947776779160f55aa47f1f8.jpg | IoU: 0.7926 | AP50: 0.2345 | AP75: 0.2345 | mAP: 0.2345 | mAP: 0.2345 | fn_ratio: 0.0054 | fp_ratio: 0.0891 |  tp_ratio: 0.2291\n",
      "Image: 000000005993_png.rf.3459be7a8ba7c2dc7f73edc5d5ea9a44.jpg | IoU: 0.7521 | AP50: 0.2272 | AP75: 0.2272 | mAP: 0.2272 | mAP: 0.2272 | fn_ratio: 0.0698 | fp_ratio: 0.0270 |  tp_ratio: 0.1573\n",
      "Image: 000000007975_png.rf.4723f5d025e77aa0932010c664cfa2a0.jpg | IoU: 0.5662 | AP50: 0.0531 | AP75: 0.0531 | mAP: 0.0531 | mAP: 0.0531 | fn_ratio: 0.0005 | fp_ratio: 0.1367 |  tp_ratio: 0.0526\n",
      "Image: 000000003799_png.rf.2200a975047c361d8e276ee03ed7fb29.jpg | IoU: 0.4928 | AP50: 0.0685 | AP75: 0.0685 | mAP: 0.0685 | mAP: 0.0685 | fn_ratio: 0.0252 | fp_ratio: 0.1656 |  tp_ratio: 0.0433\n",
      "Image: 000000003553_png.rf.630297ef7a989a1c579d34bad971de50.jpg | IoU: 0.6734 | AP50: 0.0850 | AP75: 0.0850 | mAP: 0.0850 | mAP: 0.0850 | fn_ratio: 0.0510 | fp_ratio: 0.0001 |  tp_ratio: 0.0340\n",
      "Image: 000000008232_png.rf.31e68c958ca909d5de3745dbea47a972.jpg | IoU: 0.8829 | AP50: 0.1239 | AP75: 0.1239 | mAP: 0.1239 | mAP: 0.1239 | fn_ratio: 0.0201 | fp_ratio: 0.0066 |  tp_ratio: 0.1039\n",
      "Image: 000000004750_png.rf.41f12eab57852f68839654b40cf7752e.jpg | IoU: 0.7393 | AP50: 0.2519 | AP75: 0.2519 | mAP: 0.2519 | mAP: 0.2519 | fn_ratio: 0.0874 | fp_ratio: 0.0193 |  tp_ratio: 0.1645\n",
      "Image: 000000005549_png.rf.57be213c2e4cfec28e329d6fba4002a3.jpg | IoU: 0.8124 | AP50: 0.1716 | AP75: 0.1716 | mAP: 0.1716 | mAP: 0.1716 | fn_ratio: 0.0223 | fp_ratio: 0.0417 |  tp_ratio: 0.1493\n",
      "Image: 000000003537_png.rf.47308245be44358eabfd94bd7f4b857b.jpg | IoU: 0.5406 | AP50: 0.3349 | AP75: 0.3349 | mAP: 0.3349 | mAP: 0.3349 | fn_ratio: 0.2210 | fp_ratio: 0.0046 |  tp_ratio: 0.1140\n",
      "Image: 000000004781_png.rf.54c7d43e5154a434f6e15d47659cc951.jpg | IoU: 0.8164 | AP50: 0.4582 | AP75: 0.4582 | mAP: 0.4582 | mAP: 0.4582 | fn_ratio: 0.0388 | fp_ratio: 0.0619 |  tp_ratio: 0.4194\n",
      "Image: 000000007455_png.rf.0451f9806e4f16b555419da50659163c.jpg | IoU: 0.6838 | AP50: 0.0605 | AP75: 0.0605 | mAP: 0.0605 | mAP: 0.0605 | fn_ratio: 0.0355 | fp_ratio: 0.0012 |  tp_ratio: 0.0250\n",
      "Image: 000000005825_png.rf.59fc810b0b0076811ef16082529fa594.jpg | IoU: 0.8777 | AP50: 0.1679 | AP75: 0.1679 | mAP: 0.1679 | mAP: 0.1679 | fn_ratio: 0.0127 | fp_ratio: 0.0258 |  tp_ratio: 0.1552\n",
      "Image: 000000001795_png.rf.6b3fcb93f5eb339e6134d99718b71eb4.jpg | IoU: 0.5845 | AP50: 0.3037 | AP75: 0.3037 | mAP: 0.3037 | mAP: 0.3037 | fn_ratio: 0.1793 | fp_ratio: 0.0147 |  tp_ratio: 0.1244\n",
      "Image: 000000003816_png.rf.75c74a5ae5f8d1ee4e0c2683f756846b.jpg | IoU: 0.5719 | AP50: 0.7344 | AP75: 0.7344 | mAP: 0.7344 | mAP: 0.7344 | fn_ratio: 0.0316 | fp_ratio: 0.1594 |  tp_ratio: 0.7027\n",
      "Image: 000000003277_png.rf.72382a5a92bdf0a6d13eb0f18f45fc40.jpg | IoU: 0.7262 | AP50: 0.0754 | AP75: 0.0754 | mAP: 0.0754 | mAP: 0.0754 | fn_ratio: 0.0152 | fp_ratio: 0.0419 |  tp_ratio: 0.0602\n",
      "Image: 000000003796_png.rf.791f9cbd89db01c022137fbc3c4b3e70.jpg | IoU: 0.7171 | AP50: 0.2317 | AP75: 0.2317 | mAP: 0.2317 | mAP: 0.2317 | fn_ratio: 0.0976 | fp_ratio: 0.0090 |  tp_ratio: 0.1341\n",
      "Image: 000000008471_png.rf.83d758a4b38b3fe621edcd8994a98cd7.jpg | IoU: 0.5983 | AP50: 0.1422 | AP75: 0.1422 | mAP: 0.1422 | mAP: 0.1422 | fn_ratio: 0.0213 | fp_ratio: 0.1589 |  tp_ratio: 0.1209\n",
      "Image: 000000006259_png.rf.94dd432835c9f7425473a4288303753a.jpg | IoU: 0.7981 | AP50: 0.3588 | AP75: 0.3588 | mAP: 0.3588 | mAP: 0.3588 | fn_ratio: 0.0101 | fp_ratio: 0.0984 |  tp_ratio: 0.3487\n",
      "Image: 000000004474_png.rf.799d63faeb1364c362d9f584ce51cfeb.jpg | IoU: 0.4059 | AP50: 0.2381 | AP75: 0.2381 | mAP: 0.2381 | mAP: 0.2381 | fn_ratio: 0.0777 | fp_ratio: 0.3211 |  tp_ratio: 0.1604\n",
      "Image: 000000005787_png.rf.7dbb09f8e6dda475314a3792fec219df.jpg | IoU: 0.7156 | AP50: 0.1061 | AP75: 0.1061 | mAP: 0.1061 | mAP: 0.1061 | fn_ratio: 0.0481 | fp_ratio: 0.0113 |  tp_ratio: 0.0580\n",
      "Image: 000000004710_png.rf.85d6c9e5c26ad9283190bfd1945d2bc6.jpg | IoU: 0.5714 | AP50: 0.5015 | AP75: 0.5015 | mAP: 0.5015 | mAP: 0.5015 | fn_ratio: 0.0730 | fp_ratio: 0.1964 |  tp_ratio: 0.4285\n",
      "Image: 000000002226_png.rf.84f0c56eae7ca6d5d3ce59dc87b961c4.jpg | IoU: 0.9077 | AP50: 0.0598 | AP75: 0.0598 | mAP: 0.0598 | mAP: 0.0598 | fn_ratio: 0.0069 | fp_ratio: 0.0041 |  tp_ratio: 0.0529\n",
      "Image: 000000004018_png.rf.89d336d1c46c22f3b857fdec440411da.jpg | IoU: 0.9567 | AP50: 0.2384 | AP75: 0.2384 | mAP: 0.2384 | mAP: 0.2384 | fn_ratio: 0.0067 | fp_ratio: 0.0095 |  tp_ratio: 0.2316\n",
      "Image: 000000001804_png.rf.988d4e330cfa944e35e963ee58367871.jpg | IoU: 0.6402 | AP50: 0.1336 | AP75: 0.1336 | mAP: 0.1336 | mAP: 0.1336 | fn_ratio: 0.0716 | fp_ratio: 0.0271 |  tp_ratio: 0.0620\n",
      "Image: 000000002763_png.rf.95ca205ac8cad351a45dac8cdc9b221b.jpg | IoU: 0.6186 | AP50: 0.0693 | AP75: 0.0693 | mAP: 0.0693 | mAP: 0.0693 | fn_ratio: 0.0400 | fp_ratio: 0.0266 |  tp_ratio: 0.0293\n",
      "Image: 000000003043_png.rf.81a112d6b3bcd7dda6136f355722e511.jpg | IoU: 0.7501 | AP50: 0.2754 | AP75: 0.2754 | mAP: 0.2754 | mAP: 0.2754 | fn_ratio: 0.0690 | fp_ratio: 0.0451 |  tp_ratio: 0.2064\n",
      "Image: 000000005535_png.rf.a02921fe16a2a8f143e04f36db7517de.jpg | IoU: 0.8136 | AP50: 0.1367 | AP75: 0.1367 | mAP: 0.1367 | mAP: 0.1367 | fn_ratio: 0.0399 | fp_ratio: 0.0060 |  tp_ratio: 0.0968\n",
      "Image: 000000003803_png.rf.9bc950d689c3dec7faaaf0efa51673a9.jpg | IoU: 0.8321 | AP50: 0.8476 | AP75: 0.8476 | mAP: 0.8476 | mAP: 0.8476 | fn_ratio: 0.0245 | fp_ratio: 0.0249 |  tp_ratio: 0.8231\n",
      "Image: 000000006281_png.rf.a1d6e3ae88cf554f95dda8f10d826d82.jpg | IoU: 0.6449 | AP50: 0.1422 | AP75: 0.1422 | mAP: 0.1422 | mAP: 0.1422 | fn_ratio: 0.0469 | fp_ratio: 0.0797 |  tp_ratio: 0.0953\n",
      "Image: 000000003586_png.rf.a335373803ff652f183cdfc219d6c23e.jpg | IoU: 0.7376 | AP50: 0.2216 | AP75: 0.2216 | mAP: 0.2216 | mAP: 0.2216 | fn_ratio: 0.0871 | fp_ratio: 0.0081 |  tp_ratio: 0.1344\n",
      "Image: 000000001796_png.rf.a3d3f82f164faf35f32a4de81f94f274.jpg | IoU: 0.7796 | AP50: 0.2722 | AP75: 0.2722 | mAP: 0.2722 | mAP: 0.2722 | fn_ratio: 0.0465 | fp_ratio: 0.0548 |  tp_ratio: 0.2257\n",
      "Image: 000000005517_png.rf.ac1a33be20f19db4c2621c552926f88d.jpg | IoU: 0.4637 | AP50: 0.0727 | AP75: 0.0727 | mAP: 0.0727 | mAP: 0.0727 | fn_ratio: 0.0727 | fp_ratio: 0.0000 |  tp_ratio: 0.0000\n",
      "Image: 000000001538_png.rf.b4f8df23370ab8108cba094cde6009c5.jpg | IoU: 0.7601 | AP50: 0.6942 | AP75: 0.6942 | mAP: 0.6942 | mAP: 0.6942 | fn_ratio: 0.0370 | fp_ratio: 0.0769 |  tp_ratio: 0.6572\n",
      "Image: 000000005017_png.rf.b6f9eac7ce7ccc7092bc06a7166e7642.jpg | IoU: 0.6237 | AP50: 0.0997 | AP75: 0.0997 | mAP: 0.0997 | mAP: 0.0997 | fn_ratio: 0.0425 | fp_ratio: 0.0607 |  tp_ratio: 0.0572\n",
      "Image: 000000005758_png.rf.b79080a16755615a604233e7dbd33977.jpg | IoU: 0.6449 | AP50: 0.0787 | AP75: 0.0787 | mAP: 0.0787 | mAP: 0.0787 | fn_ratio: 0.0115 | fp_ratio: 0.0898 |  tp_ratio: 0.0671\n",
      "Image: 000000004728_png.rf.b9b50cb3e9fb7f95e82dad20281f9139.jpg | IoU: 0.5128 | AP50: 0.8448 | AP75: 0.8448 | mAP: 0.8448 | mAP: 0.8448 | fn_ratio: 0.1290 | fp_ratio: 0.0830 |  tp_ratio: 0.7158\n",
      "Image: 000000006022_png.rf.c2702747520ba33faa2cb2cab3fa6e6c.jpg | IoU: 0.8679 | AP50: 0.3635 | AP75: 0.3635 | mAP: 0.3635 | mAP: 0.3635 | fn_ratio: 0.0502 | fp_ratio: 0.0142 |  tp_ratio: 0.3134\n",
      "Image: 000000006257_png.rf.c3e4f3f5602af7b8109a1b391214aa8d.jpg | IoU: 0.6391 | AP50: 0.0745 | AP75: 0.0745 | mAP: 0.0745 | mAP: 0.0745 | fn_ratio: 0.0420 | fp_ratio: 0.0205 |  tp_ratio: 0.0325\n",
      "Image: 000000003519_png.rf.c3843cf262c305ab579ad529469395e0.jpg | IoU: 0.5372 | AP50: 0.7649 | AP75: 0.7649 | mAP: 0.7649 | mAP: 0.7649 | fn_ratio: 0.1863 | fp_ratio: 0.0733 |  tp_ratio: 0.5786\n",
      "Image: 000000001812_png.rf.c59f03efa3635538436035e8b244246c.jpg | IoU: 0.8353 | AP50: 0.1032 | AP75: 0.1032 | mAP: 0.1032 | mAP: 0.1032 | fn_ratio: 0.0161 | fp_ratio: 0.0196 |  tp_ratio: 0.0872\n",
      "Image: 000000005014_png.rf.c5d42fae27a4fc608133f4435e13e1f0.jpg | IoU: 0.7095 | AP50: 0.1201 | AP75: 0.1201 | mAP: 0.1201 | mAP: 0.1201 | fn_ratio: 0.0321 | fp_ratio: 0.0521 |  tp_ratio: 0.0880\n",
      "Image: 000000002766_png.rf.c6cc7136f5f43d763e150df46e27e782.jpg | IoU: 0.5025 | AP50: 0.1423 | AP75: 0.1423 | mAP: 0.1423 | mAP: 0.1423 | fn_ratio: 0.0113 | fp_ratio: 0.2643 |  tp_ratio: 0.1310\n",
      "Image: 000000004742_png.rf.cc57aeed23144d4b0c0b0bcc34104801.jpg | IoU: 0.5476 | AP50: 0.0605 | AP75: 0.0605 | mAP: 0.0605 | mAP: 0.0605 | fn_ratio: 0.0516 | fp_ratio: 0.0000 |  tp_ratio: 0.0089\n",
      "Image: 000000007718_png.rf.d3a782b5fa5af58f7684dafb97c6678d.jpg | IoU: 0.6955 | AP50: 0.1148 | AP75: 0.1148 | mAP: 0.1148 | mAP: 0.1148 | fn_ratio: 0.0547 | fp_ratio: 0.0145 |  tp_ratio: 0.0601\n",
      "Image: 000000003057_png.rf.d3408c99dc3112e83b4628ffd3853e23.jpg | IoU: 0.9264 | AP50: 0.2008 | AP75: 0.2008 | mAP: 0.2008 | mAP: 0.2008 | fn_ratio: 0.0218 | fp_ratio: 0.0021 |  tp_ratio: 0.1789\n",
      "Image: 000000004749_png.rf.d7edc6036d494e2d745fe9c6616c9854.jpg | IoU: 0.4754 | AP50: 0.0876 | AP75: 0.0876 | mAP: 0.0876 | mAP: 0.0876 | fn_ratio: 0.0845 | fp_ratio: 0.0001 |  tp_ratio: 0.0031\n",
      "Image: 000000007184_png.rf.d768c4168c1efb5b4de89433d0e1c173.jpg | IoU: 0.9256 | AP50: 0.1126 | AP75: 0.1126 | mAP: 0.1126 | mAP: 0.1126 | fn_ratio: 0.0084 | fp_ratio: 0.0074 |  tp_ratio: 0.1042\n",
      "Image: 000000007701_png.rf.ed5873b00f37982920c0f347e69d7628.jpg | IoU: 0.7763 | AP50: 0.1320 | AP75: 0.1320 | mAP: 0.1320 | mAP: 0.1320 | fn_ratio: 0.0364 | fp_ratio: 0.0227 |  tp_ratio: 0.0956\n",
      "Image: 000000003528_png.rf.e36e6ffc51b4e36628a92461469d8909.jpg | IoU: 0.8548 | AP50: 0.5448 | AP75: 0.5448 | mAP: 0.5448 | mAP: 0.5448 | fn_ratio: 0.0713 | fp_ratio: 0.0069 |  tp_ratio: 0.4735\n",
      "Image: 000000004756_png.rf.dee9961066416de778f9bd356a104a1b.jpg | IoU: 0.4537 | AP50: 0.0800 | AP75: 0.0800 | mAP: 0.0800 | mAP: 0.0800 | fn_ratio: 0.0001 | fp_ratio: 0.2859 |  tp_ratio: 0.0798\n",
      "Image: 000000003265_png.rf.e255c83dffe99edcd6929bd8ffa69c6e.jpg | IoU: 0.6331 | AP50: 0.2282 | AP75: 0.2282 | mAP: 0.2282 | mAP: 0.2282 | fn_ratio: 0.0851 | fp_ratio: 0.0821 |  tp_ratio: 0.1431\n",
      "Image: 000000004986_png.rf.ee98630da72b10f8c194fd1d26a5c398.jpg | IoU: 0.7439 | AP50: 0.3183 | AP75: 0.3183 | mAP: 0.3183 | mAP: 0.3183 | fn_ratio: 0.0089 | fp_ratio: 0.1304 |  tp_ratio: 0.3094\n",
      "Image: 000000005786_png.rf.e35e5101d50162dc6597b0b5af29f4d5.jpg | IoU: 0.8467 | AP50: 0.1853 | AP75: 0.1853 | mAP: 0.1853 | mAP: 0.1853 | fn_ratio: 0.0258 | fp_ratio: 0.0260 |  tp_ratio: 0.1596\n",
      "Image: 000000005235_png.rf.e4bcacf0eb0d3575ee0746256e880bc8.jpg | IoU: 0.8347 | AP50: 0.2500 | AP75: 0.2500 | mAP: 0.2500 | mAP: 0.2500 | fn_ratio: 0.0511 | fp_ratio: 0.0147 |  tp_ratio: 0.1990\n",
      "Image: 000000004755_png.rf.f28b2fb7f8ba61074a22afdec778485f.jpg | IoU: 0.5333 | AP50: 0.2233 | AP75: 0.2233 | mAP: 0.2233 | mAP: 0.2233 | fn_ratio: 0.0975 | fp_ratio: 0.1439 |  tp_ratio: 0.1258\n",
      "Image: 000000003790_png.rf.eacda8044fc29437a437982318b59d4c.jpg | IoU: 0.6055 | AP50: 0.0754 | AP75: 0.0754 | mAP: 0.0754 | mAP: 0.0754 | fn_ratio: 0.0486 | fp_ratio: 0.0196 |  tp_ratio: 0.0267\n",
      "Image: 000000003648_png.rf.ebaf4dd60cde100dc3bb3680a69eb85c.jpg | IoU: 0.5437 | AP50: 0.3630 | AP75: 0.3630 | mAP: 0.3630 | mAP: 0.3630 | fn_ratio: 0.1394 | fp_ratio: 0.1387 |  tp_ratio: 0.2236\n",
      "Image: 000000004472_png.rf.f61d25ccde77e981b3396098cdbd636a.jpg | IoU: 0.5364 | AP50: 0.0834 | AP75: 0.0834 | mAP: 0.0834 | mAP: 0.0834 | fn_ratio: 0.0456 | fp_ratio: 0.0919 |  tp_ratio: 0.0378\n",
      "Image: 000000004777_png.rf.e8d8112e88f30557d7cceb4cf070dfd5.jpg | IoU: 0.5354 | AP50: 0.3964 | AP75: 0.3964 | mAP: 0.3964 | mAP: 0.3964 | fn_ratio: 0.2371 | fp_ratio: 0.0229 |  tp_ratio: 0.1594\n",
      "Image: 000000003804_png.rf.f8f4d8dd876a15bd37f7e87dd95af1ed.jpg | IoU: 0.8272 | AP50: 0.4346 | AP75: 0.4346 | mAP: 0.4346 | mAP: 0.4346 | fn_ratio: 0.0861 | fp_ratio: 0.0046 |  tp_ratio: 0.3485\n",
      "Image: 000000003304_png.rf.fd7bfdefc661f6304d179b6d0dba2921.jpg | IoU: 0.7058 | AP50: 0.1398 | AP75: 0.1398 | mAP: 0.1398 | mAP: 0.1398 | fn_ratio: 0.0264 | fp_ratio: 0.0756 |  tp_ratio: 0.1134\n",
      "Image: 000000005986_png.rf.f4e5dbf37885ec655937cff542d3e2bc.jpg | IoU: 0.7605 | AP50: 0.0652 | AP75: 0.0652 | mAP: 0.0652 | mAP: 0.0652 | fn_ratio: 0.0135 | fp_ratio: 0.0265 |  tp_ratio: 0.0516\n",
      "Image: 000000003838_png.rf.f7cc2a2822bd9585868f743e43c2a958.jpg | IoU: 0.8889 | AP50: 0.0879 | AP75: 0.0879 | mAP: 0.0879 | mAP: 0.0879 | fn_ratio: 0.0024 | fp_ratio: 0.0189 |  tp_ratio: 0.0855\n",
      "IoU results saved to SS_Rio_tile1024_stride0.v1i.coco-segmentation/test\\segmentation_results_fp_fn\\iou_results.csv\n"
     ]
    }
   ],
   "source": [
    "# improved \n",
    "\n",
    "\n",
    "\n",
    "# Initialize Roboflow and model\n",
    "# rf = Roboflow(api_key=\"uZgVV5Mu30Veqelqd61T\")\n",
    "# project = rf.workspace().project(\"ss-tijuca2019_tile400_stride0\")\n",
    "# model = project.version(\"1\").model  # Specify version\n",
    "\n",
    "# # Input and output directories\n",
    "# image_dir = 'SS-Tijuca2019_tile400_stride0.v1i.coco-segmentation/test'\n",
    "\n",
    "\n",
    "# Initialize Roboflow and model\n",
    "rf = Roboflow(api_key=\"uZgVV5Mu30Veqelqd61T\")\n",
    "project = rf.workspace().project(\"ss_rio_tile1024_stride0\") # input model id\n",
    "model = project.version(\"1\").model # input model version\n",
    "\n",
    "# Input and output directories\n",
    "image_dir = 'SS_Rio_tile1024_stride0.v1i.coco-segmentation/test'\n",
    "\n",
    "\n",
    "coco_json_path = os.path.join(image_dir, \"_annotations.coco.json\")\n",
    "output_dir = os.path.join(image_dir, \"segmentation_results_fp_fn\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize CSV for IoU results\n",
    "iou_csv_path = os.path.join(output_dir, \"iou_results.csv\")\n",
    "with open(iou_csv_path, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"Image Name\", \"IoU\", \"AP50\", \"AP75\", \"mAP\", \"fn_ratio\", \"fp_ratio\", \"tp_ratio\"])\n",
    "\n",
    "    with open(coco_json_path) as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    image_ids = [image['id'] for image in coco_data['images']]\n",
    "    threshold_list = np.linspace(0.5, 0.95, 10)  # IoU thresholds for mAP\n",
    "    \n",
    "    for image_id in image_ids:\n",
    "        if image_id != -1: \n",
    "            image_info = next(img for img in coco_data['images'] if img['id'] == image_id)\n",
    "            image_file_name = image_info['file_name']\n",
    "            img_path = os.path.join(image_dir, image_file_name)\n",
    "\n",
    "            # Load ground truth annotations\n",
    "            gt_annotations = [anno for anno in coco_data['annotations'] if anno['image_id'] == image_id]\n",
    "            im = cv2.imread(img_path)\n",
    "            gt_mask = np.zeros((im.shape[0], im.shape[1]), dtype=np.uint8)\n",
    "\n",
    "            for annotation in gt_annotations:\n",
    "                segmentation = annotation['segmentation'][0]\n",
    "                points = [(segmentation[i], segmentation[i + 1]) for i in range(0, len(segmentation), 2)]\n",
    "                cv2.fillPoly(gt_mask, [np.array(points, dtype=np.int32)], 1)\n",
    "\n",
    "            # Perform inference\n",
    "            result = model.predict(img_path)\n",
    "            prediction = result.json()\n",
    "\n",
    "            if not prediction['predictions']:\n",
    "                print(f\"No predictions for {image_file_name}. Skipping.\")\n",
    "                csv_writer.writerow([image_file_name, \"No predictions\"])\n",
    "                continue\n",
    "\n",
    "            # Decode prediction mask\n",
    "            segmentation_mask_b64 = prediction['predictions'][0]['segmentation_mask']\n",
    "            decoded_mask = base64.b64decode(segmentation_mask_b64)\n",
    "            pred_mask = np.array(Image.open(io.BytesIO(decoded_mask)))\n",
    "\n",
    "            # Resize pred_mask to match gt_mask dimensions\n",
    "            pred_mask_resized = cv2.resize(pred_mask, (gt_mask.shape[1], gt_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "            pred_mask_resized = (pred_mask_resized > 0).astype(np.uint8) \n",
    "\n",
    "\n",
    "\n",
    "            # Flatten masks for precision-recall computation\n",
    "            gt_flat = (gt_mask.flatten() > 0).astype(np.uint8)  # Ensure ground truth values are {0, 1}\n",
    "            pred_flat = pred_mask_resized.flatten() / 255.0\n",
    "\n",
    "            # Calculate Precision-Recall curve\n",
    "            precision, recall, _ = precision_recall_curve(gt_flat, pred_flat)\n",
    "            ap50 = average_precision_score(gt_flat, pred_flat)  # AP50 calculation\n",
    "\n",
    "            # Calculate AP at each IoU threshold\n",
    "            ap_values = []\n",
    "            for threshold in threshold_list:\n",
    "                pred_binary = (pred_flat >= threshold * 255).astype(np.uint8)  # Binarize predictions\n",
    "                precision, recall, _ = precision_recall_curve(gt_flat, pred_binary)\n",
    "                ap = average_precision_score(gt_flat, pred_binary)\n",
    "                ap_values.append(ap)\n",
    "\n",
    "            # Extract AP50 and AP75\n",
    "            ap50 = ap_values[0]  # First value corresponds to IoU=0.5\n",
    "            ap75 = ap_values[5]  # Sixth value corresponds to IoU=0.75\n",
    "            mAP = np.mean(ap_values)  # Mean of all AP values\n",
    "\n",
    "            \n",
    "            # Construct confusion matrix for binary segmentation\n",
    "            conf_matrix = np.zeros((2, 2), dtype=np.int32)\n",
    "            for gt, pred in zip(gt_flat, (pred_flat >= 0.5).astype(np.uint8)):\n",
    "                conf_matrix[gt, pred] += 1\n",
    "\n",
    "            # Error mask\n",
    "            error_mask = cv2.bitwise_and(gt_mask, cv2.bitwise_not(pred_mask_resized))\n",
    "            fn_mask = cv2.bitwise_and(gt_mask, cv2.bitwise_not(pred_mask_resized))          # False Negative (FN): Ground Truth is 1, Prediction is 0\n",
    "            fp_mask = cv2.bitwise_and(pred_mask_resized, cv2.bitwise_not(gt_mask))        # False Positive (FP): Prediction is 1, Ground Truth is 0\n",
    "            tp_mask = cv2.bitwise_and(gt_mask, pred_mask_resized)\n",
    "\n",
    "            # IoU calculation\n",
    "            # gt_binary = (gt_mask > 0).astype(np.uint8)\n",
    "            # pred_binary = (pred_mask_resized > 0).astype(np.uint8)\n",
    "\n",
    "            # intersection = np.logical_and(gt_binary, pred_binary).sum()\n",
    "            # union = np.logical_or(gt_binary, pred_binary).sum()\n",
    "            # iou = intersection / union if union > 0 else 0\n",
    "\n",
    "            iou = compute_iou_for_each_class(gt_mask,pred_mask_resized,2)\n",
    "\n",
    "            # Calculate FN, FP, and TP counts\n",
    "            fn_count = np.sum(fn_mask)\n",
    "            fp_count = np.sum(fp_mask)\n",
    "            tp_count = np.sum(gt_mask & pred_mask_resized)\n",
    "            total_pixels = gt_mask.size\n",
    "\n",
    "            # Calculate ratios\n",
    "            fn_ratio = fn_count / total_pixels\n",
    "            fp_ratio = fp_count / total_pixels\n",
    "            tp_ratio = tp_count / total_pixels\n",
    "\n",
    "            # Write to CSV\n",
    "            csv_writer.writerow([image_file_name, iou, ap50, ap75, mAP, fn_ratio, fp_ratio, tp_ratio])\n",
    "\n",
    "            # Visualization: overlay ground truth and prediction on the original image\n",
    "            original_image = Image.open(img_path).convert(\"RGBA\")\n",
    "\n",
    "            # Ground truth overlay\n",
    "            overlay_gt = Image.new(\"RGBA\", original_image.size, (255, 255, 255, 0))\n",
    "            draw_gt = ImageDraw.Draw(overlay_gt)\n",
    "            for annotation in gt_annotations:\n",
    "                segmentation = annotation['segmentation'][0]\n",
    "                points = [(segmentation[i], segmentation[i + 1]) for i in range(0, len(segmentation), 2)]\n",
    "                draw_gt.polygon(points, fill=(255, 255, 255, 100))  # Semi-transparent red for ground truth\n",
    "            combined_gt = Image.alpha_composite(original_image, overlay_gt)\n",
    "\n",
    "            # Prediction overlay\n",
    "            overlay_pred = Image.new(\"RGBA\", original_image.size, (255, 255, 255, 0))\n",
    "            draw_pred = ImageDraw.Draw(overlay_pred)\n",
    "            pred_mask_pil = Image.fromarray(pred_mask_resized)\n",
    "            draw_pred.bitmap((0, 0), pred_mask_pil, fill=(0, 0, 255, 30))  # Semi-transparent blue for prediction\n",
    "            combined_pred = Image.alpha_composite(original_image, overlay_pred)\n",
    "\n",
    "\n",
    "\n",
    "            # # Create a PIL image with black background and white error regions\n",
    "            # error_image = Image.fromarray(\n",
    "            #     np.where(\n",
    "            #         error_mask[..., None] == 255,  # Condition for error pixels\n",
    "            #         [255, 255, 255, 255],         # White for error pixels\n",
    "            #         [0, 0, 0, 255]                # Black for non-error pixels\n",
    "            #     ).astype(np.uint8)\n",
    "            # )\n",
    "\n",
    "            # Error overlay (FN in red, FP in blue)\n",
    "            overlay_error = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 255))\n",
    "            fn_pil = Image.fromarray((fn_mask > 0).astype(np.uint8) * 255).convert(\"L\")\n",
    "            fp_pil = Image.fromarray((fp_mask > 0).astype(np.uint8) * 255).convert(\"L\")\n",
    "            tp_pil = Image.fromarray((tp_mask > 0).astype(np.uint8) * 255).convert(\"L\")\n",
    "            error_draw = ImageDraw.Draw(overlay_error)\n",
    "            error_draw.bitmap((0, 0), fn_pil, fill=(255, 0, 0, 100))  # Red for False Negative, (255, 0, 0, 100)   (50, 50, 50, 255)\n",
    "            error_draw.bitmap((0, 0), fp_pil, fill=(0, 0, 255, 100))  # Blue for False Positive,(0, 0, 255, 100)   (200, 200, 200, 255)\n",
    "            error_draw.bitmap((0, 0), tp_pil, fill=(255, 255, 255, 255)) \n",
    "            combined_error = overlay_error\n",
    "\n",
    "            # Plot results\n",
    "            # fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "            # axs[0].imshow(original_image)\n",
    "            # axs[0].axis('off')\n",
    "            # axs[0].set_title('Original Image')\n",
    "\n",
    "            # axs[1].imshow(combined_gt)\n",
    "            # axs[1].axis('off')\n",
    "            # axs[1].set_title('Ground Truth Overlay')\n",
    "\n",
    "            # axs[2].imshow(combined_pred)\n",
    "            # axs[2].axis('off')\n",
    "            # axs[2].set_title('Prediction Overlay')\n",
    "\n",
    "            # # axs[3].imshow(error_image)\n",
    "            # # Error Map (False Positive & False Negative)\n",
    "            # axs[3].imshow(np.array(combined_error))  # Error visualization (FN & FP)\n",
    "            # axs[3].axis('off')\n",
    "            # axs[3].set_title(f'Error (IoU: {iou:.4f})')\n",
    "\n",
    "            # save img\n",
    "            # output_path = os.path.join(output_dir, f\"{image_file_name}_result.png\")\n",
    "\n",
    "            # images = [original_image, combined_gt, combined_pred, combined_error]\n",
    "            # labels = [\"Original Image\", \"Ground Truth\", \"Prediction\", \"Error Map\"]\n",
    "            # final_image = combine_images_with_labels(images, labels, iou=iou, border_width=30, font_size=30,outer_margin=30)\n",
    "            # final_image.save(output_path)\n",
    "            \n",
    "            # plt.savefig(output_path, bbox_inches='tight', pad_inches=0.1)\n",
    "            # plt.close(fig)\n",
    "            # plt.show()\n",
    "\n",
    "            print(f\"Image: {image_file_name} | IoU: {iou:.4f} | AP50: {ap50:.4f} | AP75: {ap75:.4f} | mAP: {mAP:.4f} | mAP: {mAP:.4f} | fn_ratio: {fn_ratio:.4f} | fp_ratio: {fp_ratio:.4f} |  tp_ratio: {tp_ratio:.4f}\")\n",
    "\n",
    "print(f\"IoU results saved to {iou_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn_mask.shape)\n",
    "print(np.unique(fn_mask))\n",
    "\n",
    "print(fp_mask.shape)\n",
    "print(np.unique(fp_mask))\n",
    "\n",
    "print(gt_mask.shape)\n",
    "print(np.unique(gt_mask))\n",
    "\n",
    "print(pred_mask_resized.shape)\n",
    "print(np.unique(pred_mask_resized))\n",
    "\n",
    "print(tp_count.shape)\n",
    "print(np.unique(tp_count))\n",
    "\n",
    "print(gt_mask.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn_count)\n",
    "print(fp_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tp_count) \n",
    "print(total_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improved \n",
    "\n",
    "\n",
    "\n",
    "# Initialize Roboflow and model\n",
    "# rf = Roboflow(api_key=\"uZgVV5Mu30Veqelqd61T\")\n",
    "# project = rf.workspace().project(\"ss-tijuca2019_tile400_stride0\")\n",
    "# model = project.version(\"1\").model  # Specify version\n",
    "\n",
    "# # Input and output directories\n",
    "# image_dir = 'SS-Tijuca2019_tile400_stride0.v1i.coco-segmentation/test'\n",
    "\n",
    "\n",
    "# Initialize Roboflow and model\n",
    "rf = Roboflow(api_key=\"uZgVV5Mu30Veqelqd61T\")\n",
    "project = rf.workspace().project(\"ss_rio_tile1024_stride0\") # input model id\n",
    "model = project.version(\"1\").model # input model version\n",
    "\n",
    "# Input and output directories\n",
    "image_dir = 'SS_Rio_tile1024_stride0.v1i.coco-segmentation/test'\n",
    "\n",
    "\n",
    "coco_json_path = os.path.join(image_dir, \"_annotations.coco.json\")\n",
    "output_dir = os.path.join(image_dir, \"segmentation_results_fp_fn\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize CSV for IoU results\n",
    "iou_csv_path = os.path.join(output_dir, \"iou_results.csv\")\n",
    "with open(iou_csv_path, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"Image Name\", \"IoU\", \"AP50\", \"AP75\", \"mAP\", \"fn_ratio\", \"fp_ratio\", \"tp_ratio\"])\n",
    "\n",
    "    with open(coco_json_path) as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    image_ids = [image['id'] for image in coco_data['images']]\n",
    "    threshold_list = np.linspace(0.5, 0.95, 10)  # IoU thresholds for mAP\n",
    "    \n",
    "    for image_id in image_ids:\n",
    "        image_info = next(img for img in coco_data['images'] if img['id'] == image_id)\n",
    "        image_file_name = image_info['file_name']\n",
    "        img_path = os.path.join(image_dir, image_file_name)\n",
    "\n",
    "        # Load ground truth annotations\n",
    "        gt_annotations = [anno for anno in coco_data['annotations'] if anno['image_id'] == image_id]\n",
    "        im = cv2.imread(img_path)\n",
    "        gt_mask = np.zeros((im.shape[0], im.shape[1]), dtype=np.uint8)\n",
    "\n",
    "        for annotation in gt_annotations:\n",
    "            segmentation = annotation['segmentation'][0]\n",
    "            points = [(segmentation[i], segmentation[i + 1]) for i in range(0, len(segmentation), 2)]\n",
    "            cv2.fillPoly(gt_mask, [np.array(points, dtype=np.int32)], 255)\n",
    "\n",
    "        # Perform inference\n",
    "        result = model.predict(img_path)\n",
    "        prediction = result.json()\n",
    "\n",
    "        if not prediction['predictions']:\n",
    "            print(f\"No predictions for {image_file_name}. Skipping.\")\n",
    "            csv_writer.writerow([image_file_name, \"No predictions\"])\n",
    "            continue\n",
    "\n",
    "        # Decode prediction mask\n",
    "        segmentation_mask_b64 = prediction['predictions'][0]['segmentation_mask']\n",
    "        decoded_mask = base64.b64decode(segmentation_mask_b64)\n",
    "        pred_mask = np.array(Image.open(io.BytesIO(decoded_mask)))\n",
    "\n",
    "        # Resize pred_mask to match gt_mask dimensions\n",
    "        pred_mask_resized = cv2.resize(pred_mask, (gt_mask.shape[1], gt_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        pred_mask_resized = (pred_mask_resized > 0).astype(np.uint8) * 255\n",
    "\n",
    "\n",
    "\n",
    "        # Flatten masks for precision-recall computation\n",
    "        gt_flat = (gt_mask.flatten() > 0).astype(np.uint8)  # Ensure ground truth values are {0, 1}\n",
    "        pred_flat = pred_mask_resized.flatten() / 255.0\n",
    "\n",
    "        # Calculate Precision-Recall curve\n",
    "        precision, recall, _ = precision_recall_curve(gt_flat, pred_flat)\n",
    "        ap50 = average_precision_score(gt_flat, pred_flat)  # AP50 calculation\n",
    "\n",
    "        # Calculate AP at each IoU threshold\n",
    "        ap_values = []\n",
    "        for threshold in threshold_list:\n",
    "            pred_binary = (pred_flat >= threshold * 255).astype(np.uint8)  # Binarize predictions\n",
    "            precision, recall, _ = precision_recall_curve(gt_flat, pred_binary)\n",
    "            ap = average_precision_score(gt_flat, pred_binary)\n",
    "            ap_values.append(ap)\n",
    "\n",
    "        # Extract AP50 and AP75\n",
    "        ap50 = ap_values[0]  # First value corresponds to IoU=0.5\n",
    "        ap75 = ap_values[5]  # Sixth value corresponds to IoU=0.75\n",
    "        mAP = np.mean(ap_values)  # Mean of all AP values\n",
    "\n",
    "        \n",
    "        # Construct confusion matrix for binary segmentation\n",
    "        conf_matrix = np.zeros((2, 2), dtype=np.int32)\n",
    "        for gt, pred in zip(gt_flat, (pred_flat >= 0.5).astype(np.uint8)):\n",
    "            conf_matrix[gt, pred] += 1\n",
    "\n",
    "        # Error mask\n",
    "        error_mask = cv2.bitwise_and(gt_mask, cv2.bitwise_not(pred_mask_resized))\n",
    "        fn_mask = cv2.bitwise_and(gt_mask, cv2.bitwise_not(pred_mask_resized))          # False Negative (FN): Ground Truth is 1, Prediction is 0\n",
    "        fp_mask = cv2.bitwise_and(pred_mask_resized, cv2.bitwise_not(gt_mask))        # False Positive (FP): Prediction is 1, Ground Truth is 0\n",
    "        tp_mask = cv2.bitwise_and(gt_mask, pred_mask_resized)\n",
    "\n",
    "        # IoU calculation\n",
    "        # gt_binary = (gt_mask > 0).astype(np.uint8)\n",
    "        # pred_binary = (pred_mask_resized > 0).astype(np.uint8)\n",
    "\n",
    "        # intersection = np.logical_and(gt_binary, pred_binary).sum()\n",
    "        # union = np.logical_or(gt_binary, pred_binary).sum()\n",
    "        # iou = intersection / union if union > 0 else 0\n",
    "\n",
    "        iou = compute_iou_for_each_class(gt_mask,pred_mask_resized,2)\n",
    "\n",
    "        # Calculate FN, FP, and TP counts\n",
    "        fn_count = np.sum(fn_mask)\n",
    "        fp_count = np.sum(fp_mask)\n",
    "        tp_count = np.sum(gt_mask & pred_mask_resized)\n",
    "        total_pixels = gt_mask.size\n",
    "\n",
    "        # Calculate ratios\n",
    "        fn_ratio = fn_count / total_pixels\n",
    "        fp_ratio = fp_count / total_pixels\n",
    "        tp_ratio = tp_count / total_pixels\n",
    "\n",
    "        # Write to CSV\n",
    "        csv_writer.writerow([image_file_name, iou, ap50, ap75, mAP, fn_ratio, fp_ratio, tp_ratio])\n",
    "\n",
    "        # Visualization: overlay ground truth and prediction on the original image\n",
    "        original_image = Image.open(img_path).convert(\"RGBA\")\n",
    "\n",
    "        # Ground truth overlay\n",
    "        overlay_gt = Image.new(\"RGBA\", original_image.size, (255, 255, 255, 0))\n",
    "        draw_gt = ImageDraw.Draw(overlay_gt)\n",
    "        for annotation in gt_annotations:\n",
    "            segmentation = annotation['segmentation'][0]\n",
    "            points = [(segmentation[i], segmentation[i + 1]) for i in range(0, len(segmentation), 2)]\n",
    "            draw_gt.polygon(points, fill=(255, 255, 255, 100))  # Semi-transparent red for ground truth\n",
    "        combined_gt = Image.alpha_composite(original_image, overlay_gt)\n",
    "\n",
    "        # Prediction overlay\n",
    "        overlay_pred = Image.new(\"RGBA\", original_image.size, (255, 255, 255, 0))\n",
    "        draw_pred = ImageDraw.Draw(overlay_pred)\n",
    "        pred_mask_pil = Image.fromarray(pred_mask_resized)\n",
    "        draw_pred.bitmap((0, 0), pred_mask_pil, fill=(0, 0, 255, 30))  # Semi-transparent blue for prediction\n",
    "        combined_pred = Image.alpha_composite(original_image, overlay_pred)\n",
    "\n",
    "\n",
    "\n",
    "        # # Create a PIL image with black background and white error regions\n",
    "        # error_image = Image.fromarray(\n",
    "        #     np.where(\n",
    "        #         error_mask[..., None] == 255,  # Condition for error pixels\n",
    "        #         [255, 255, 255, 255],         # White for error pixels\n",
    "        #         [0, 0, 0, 255]                # Black for non-error pixels\n",
    "        #     ).astype(np.uint8)\n",
    "        # )\n",
    "\n",
    "        # Error overlay (FN in red, FP in blue)\n",
    "        overlay_error = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 255))\n",
    "        fn_pil = Image.fromarray((fn_mask > 0).astype(np.uint8) * 255).convert(\"L\")\n",
    "        fp_pil = Image.fromarray((fp_mask > 0).astype(np.uint8) * 255).convert(\"L\")\n",
    "        tp_pil = Image.fromarray((tp_mask > 0).astype(np.uint8) * 255).convert(\"L\")\n",
    "        error_draw = ImageDraw.Draw(overlay_error)\n",
    "        error_draw.bitmap((0, 0), fn_pil, fill=(255, 0, 0, 100))  # Red for False Negative, (255, 0, 0, 100)   (50, 50, 50, 255)\n",
    "        error_draw.bitmap((0, 0), fp_pil, fill=(0, 0, 255, 100))  # Blue for False Positive,(0, 0, 255, 100)   (200, 200, 200, 255)\n",
    "        error_draw.bitmap((0, 0), tp_pil, fill=(255, 255, 255, 255)) \n",
    "        combined_error = overlay_error\n",
    "\n",
    "        # Plot results\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        axs[0].imshow(original_image)\n",
    "        axs[0].axis('off')\n",
    "        axs[0].set_title('Original Image')\n",
    "\n",
    "        axs[1].imshow(combined_gt)\n",
    "        axs[1].axis('off')\n",
    "        axs[1].set_title('Ground Truth Overlay')\n",
    "\n",
    "        axs[2].imshow(combined_pred)\n",
    "        axs[2].axis('off')\n",
    "        axs[2].set_title('Prediction Overlay')\n",
    "\n",
    "        # axs[3].imshow(error_image)\n",
    "        # Error Map (False Positive & False Negative)\n",
    "        axs[3].imshow(np.array(combined_error))  # Error visualization (FN & FP)\n",
    "        axs[3].axis('off')\n",
    "        axs[3].set_title(f'Error (IoU: {iou:.4f})')\n",
    "\n",
    "        # save img\n",
    "        output_path = os.path.join(output_dir, f\"{image_file_name}_result.png\")\n",
    "\n",
    "        images = [original_image, combined_gt, combined_pred, combined_error]\n",
    "        labels = [\"Original Image\", \"Ground Truth\", \"Prediction\", \"Error Map\"]\n",
    "        final_image = combine_images_with_labels(images, labels, iou=iou, border_width=30, font_size=30,outer_margin=30)\n",
    "        final_image.save(output_path)\n",
    "        \n",
    "        # plt.savefig(output_path, bbox_inches='tight', pad_inches=0.1)\n",
    "        # plt.close(fig)\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Image: {image_file_name} | IoU: {iou:.4f} | AP50: {ap50:.4f} | AP75: {ap75:.4f} | mAP: {mAP:.4f}\")\n",
    "\n",
    "print(f\"IoU results saved to {iou_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "roboflow mIOU calculation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_miou(actual, predicted, num_classes):\n",
    "    \"\"\"\n",
    "    Calculate Mean Intersection over Union (mIoU).\n",
    "    \n",
    "    Parameters:\n",
    "    - actual: Ground Truth labels (2D array)\n",
    "    - predicted: Predicted labels (2D array)\n",
    "    - num_classes: Total number of classes\n",
    "    \n",
    "    Returns:\n",
    "    - mIoU: Mean IoU value\n",
    "    \"\"\"\n",
    "    # Flatten both matrices\n",
    "    actual_flat = actual.flatten()\n",
    "    predicted_flat = predicted.flatten()\n",
    "    \n",
    "    # Confusion matrix initialization\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=np.int32)\n",
    "    \n",
    "    # Populate confusion matrix\n",
    "    for i in range(len(actual_flat)):\n",
    "        confusion_matrix[actual_flat[i], predicted_flat[i]] += 1\n",
    "    \n",
    "    # Calculate IoU for each class\n",
    "    ious = []\n",
    "    for c in range(num_classes):\n",
    "        intersection = confusion_matrix[c, c]\n",
    "        union = (\n",
    "            np.sum(confusion_matrix[c, :]) +\n",
    "            np.sum(confusion_matrix[:, c]) -\n",
    "            intersection\n",
    "        )\n",
    "        if union > 0:\n",
    "            ious.append(intersection / union)\n",
    "        else:\n",
    "            ious.append(np.nan)  # Handle classes not present in the data\n",
    "    \n",
    "    # Calculate mean IoU\n",
    "    miou = np.nanmean(ious)  # Ignore NaN classes\n",
    "    return miou\n",
    "\n",
    "# Example usage\n",
    "actual = np.array([[0, 1, 1, 2], [0, 0, 2, 2], [3, 3, 4, 4], [3, 5, 5, 5]])\n",
    "predicted = np.array([[0, 1, 0, 2], [0, 0, 2, 1], [3, 3, 4, 4], [3, 5, 5, 0]])\n",
    "\n",
    "num_classes = 6  # Assuming labels are 0-5\n",
    "miou = calculate_miou(actual, predicted, num_classes)\n",
    "print(f\"Mean IoU: {miou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change detection\n",
    "\n",
    "\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import base64\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from roboflow import Roboflow\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "# Initialize Roboflow and model\n",
    "# rf = Roboflow(api_key=\"uZgVV5Mu30Veqelqd61T\")\n",
    "# project = rf.workspace().project(\"ss-tijuca2019_tile400_stride0\")\n",
    "# model = project.version(\"1\").model  # Specify version\n",
    "\n",
    "# # Input and output directories\n",
    "# image_dir = 'SS-Tijuca2019_tile400_stride0.v1i.coco-segmentation/test'\n",
    "\n",
    "\n",
    "# Initialize Roboflow and model\n",
    "rf = Roboflow(api_key=\"uZgVV5Mu30Veqelqd61T\")\n",
    "project = rf.workspace().project(\"ss_rio_tile1024_stride0\") # input model id\n",
    "model = project.version(\"1\").model # input model version\n",
    "\n",
    "# Input and output directories\n",
    "image_dir = 'SS_Rio_tile1024_stride0.v1i.coco-segmentation/test-new'\n",
    "\n",
    "\n",
    "coco_json_path = os.path.join(image_dir, \"_annotations.coco.json\")\n",
    "output_dir = os.path.join(image_dir, \"segmentation_results_fp_fn\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize CSV for IoU results\n",
    "iou_csv_path = os.path.join(output_dir, \"iou_results.csv\")\n",
    "with open(iou_csv_path, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"Image Name\", \"IoU\", \"AP50\", \"AP75\", \"mAP\"])\n",
    "\n",
    "    with open(coco_json_path) as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    image_ids = [image['id'] for image in coco_data['images']]\n",
    "    threshold_list = np.linspace(0.5, 0.95, 10)  # IoU thresholds for mAP\n",
    "    \n",
    "    for image_id in image_ids:\n",
    "        image_info = next(img for img in coco_data['images'] if img['id'] == image_id)\n",
    "        image_file_name = image_info['file_name']\n",
    "        img_path = os.path.join(image_dir, image_file_name)\n",
    "\n",
    "        # Load ground truth annotations\n",
    "        gt_annotations = [anno for anno in coco_data['annotations'] if anno['image_id'] == image_id]\n",
    "        im = cv2.imread(img_path)\n",
    "        gt_mask = np.zeros((im.shape[0], im.shape[1]), dtype=np.uint8)\n",
    "\n",
    "        for annotation in gt_annotations:\n",
    "            segmentation = annotation['segmentation'][0]\n",
    "            points = [(segmentation[i], segmentation[i + 1]) for i in range(0, len(segmentation), 2)]\n",
    "            cv2.fillPoly(gt_mask, [np.array(points, dtype=np.int32)], 255)\n",
    "\n",
    "        # Perform inference\n",
    "        result = model.predict(img_path)\n",
    "        prediction = result.json()\n",
    "\n",
    "        if not prediction['predictions']:\n",
    "            print(f\"No predictions for {image_file_name}. Skipping.\")\n",
    "            csv_writer.writerow([image_file_name, \"No predictions\"])\n",
    "            continue\n",
    "\n",
    "        # Decode prediction mask\n",
    "        segmentation_mask_b64 = prediction['predictions'][0]['segmentation_mask']\n",
    "        decoded_mask = base64.b64decode(segmentation_mask_b64)\n",
    "        pred_mask = np.array(Image.open(io.BytesIO(decoded_mask)))\n",
    "\n",
    "        # Resize pred_mask to match gt_mask dimensions\n",
    "        pred_mask_resized = cv2.resize(pred_mask, (gt_mask.shape[1], gt_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        pred_mask_resized = (pred_mask_resized > 0).astype(np.uint8) * 255\n",
    "\n",
    "        # IoU calculation\n",
    "        intersection = np.logical_and(gt_mask, pred_mask_resized).sum()\n",
    "        union = np.logical_or(gt_mask, pred_mask_resized).sum()\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "\n",
    "        # Flatten masks for precision-recall computation\n",
    "        gt_flat = (gt_mask.flatten() > 0).astype(np.uint8)  # Ensure ground truth values are {0, 1}\n",
    "        pred_flat = pred_mask_resized.flatten() / 255.0\n",
    "\n",
    "        # Calculate Precision-Recall curve\n",
    "        precision, recall, _ = precision_recall_curve(gt_flat, pred_flat)\n",
    "        ap50 = average_precision_score(gt_flat, pred_flat)  # AP50 calculation\n",
    "\n",
    "        # Calculate AP at each IoU threshold\n",
    "        ap_values = []\n",
    "        for threshold in threshold_list:\n",
    "            pred_binary = (pred_flat >= threshold * 255).astype(np.uint8)  # Binarize predictions\n",
    "            precision, recall, _ = precision_recall_curve(gt_flat, pred_binary)\n",
    "            ap = average_precision_score(gt_flat, pred_binary)\n",
    "            ap_values.append(ap)\n",
    "\n",
    "        # Extract AP50 and AP75\n",
    "        ap50 = ap_values[0]  # First value corresponds to IoU=0.5\n",
    "        ap75 = ap_values[5]  # Sixth value corresponds to IoU=0.75\n",
    "        mAP = np.mean(ap_values)  # Mean of all AP values\n",
    "\n",
    "        # Write results to CSV\n",
    "        csv_writer.writerow([image_file_name, iou, ap50, ap75, mAP])\n",
    "\n",
    "        # Visualization: overlay ground truth and prediction on the original image\n",
    "        original_image = Image.open(img_path).convert(\"RGBA\")\n",
    "\n",
    "        # Ground truth overlay\n",
    "        overlay_gt = Image.new(\"RGBA\", original_image.size, (255, 255, 255, 0))\n",
    "        draw_gt = ImageDraw.Draw(overlay_gt)\n",
    "        for annotation in gt_annotations:\n",
    "            segmentation = annotation['segmentation'][0]\n",
    "            points = [(segmentation[i], segmentation[i + 1]) for i in range(0, len(segmentation), 2)]\n",
    "            draw_gt.polygon(points, fill=(255, 255, 255, 100))  # Semi-transparent red for ground truth\n",
    "        combined_gt = Image.alpha_composite(original_image, overlay_gt)\n",
    "\n",
    "        # Prediction overlay\n",
    "        overlay_pred = Image.new(\"RGBA\", original_image.size, (255, 255, 255, 0))\n",
    "        draw_pred = ImageDraw.Draw(overlay_pred)\n",
    "        pred_mask_pil = Image.fromarray(pred_mask_resized)\n",
    "        draw_pred.bitmap((0, 0), pred_mask_pil, fill=(0, 0, 255, 30))  # Semi-transparent blue for prediction\n",
    "        combined_pred = Image.alpha_composite(original_image, overlay_pred)\n",
    "\n",
    "        # Error mask\n",
    "        error_mask = cv2.bitwise_and(gt_mask, cv2.bitwise_not(pred_mask_resized))\n",
    "\n",
    "        # False Negative (FN): Ground Truth is 1, Prediction is 0\n",
    "        fn_mask = cv2.bitwise_and(gt_mask, cv2.bitwise_not(pred_mask_resized))\n",
    "\n",
    "        # False Positive (FP): Prediction is 1, Ground Truth is 0\n",
    "        fp_mask = cv2.bitwise_and(pred_mask_resized, cv2.bitwise_not(gt_mask))\n",
    "\n",
    "        # # Create a PIL image with black background and white error regions\n",
    "        # error_image = Image.fromarray(\n",
    "        #     np.where(\n",
    "        #         error_mask[..., None] == 255,  # Condition for error pixels\n",
    "        #         [255, 255, 255, 255],         # White for error pixels\n",
    "        #         [0, 0, 0, 255]                # Black for non-error pixels\n",
    "        #     ).astype(np.uint8)\n",
    "        # )\n",
    "\n",
    "        # Error overlay (FN in red, FP in blue)\n",
    "        overlay_error = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 255))\n",
    "        fn_pil = Image.fromarray(fn_mask).convert(\"L\")\n",
    "        fp_pil = Image.fromarray(fp_mask).convert(\"L\")\n",
    "        error_draw = ImageDraw.Draw(overlay_error)\n",
    "        error_draw.bitmap((0, 0), fn_pil, fill=(255, 255, 255, 255))  # Red for False Negative, (255, 0, 0, 100)\n",
    "        error_draw.bitmap((0, 0), fp_pil, fill=(128, 128, 128, 255))  # Blue for False Positive,(0, 0, 255, 100)\n",
    "        combined_error = overlay_error\n",
    "\n",
    "        # Plot results\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        axs[0].imshow(original_image)\n",
    "        axs[0].axis('off')\n",
    "        axs[0].set_title('Original Image')\n",
    "\n",
    "        axs[1].imshow(combined_gt)\n",
    "        axs[1].axis('off')\n",
    "        axs[1].set_title('Ground Truth Overlay')\n",
    "\n",
    "        axs[2].imshow(combined_pred)\n",
    "        axs[2].axis('off')\n",
    "        axs[2].set_title('Prediction Overlay')\n",
    "\n",
    "        # axs[3].imshow(error_image)\n",
    "        # Error Map (False Positive & False Negative)\n",
    "        axs[3].imshow(np.array(combined_error))  # Error visualization (FN & FP)\n",
    "        axs[3].axis('off')\n",
    "        axs[3].set_title(f'Error (IoU: {iou:.4f})')\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"{image_file_name}_result.png\")\n",
    "\n",
    "        # Add labels to each image\n",
    "        original_with_label = add_labels(original_image, \"Original Image\")\n",
    "        gt_with_label = add_labels(combined_gt, \"Ground Truth\")\n",
    "        pred_with_label = add_labels(combined_pred, \"Prediction\")\n",
    "        error_with_label = add_labels(combined_error, \"Error Map\", iou=iou)\n",
    "\n",
    "        output_image = np.hstack([\n",
    "            np.array(original_with_label),\n",
    "            np.array(gt_with_label),\n",
    "            np.array(pred_with_label),\n",
    "            np.array(error_with_label)\n",
    "        ])\n",
    "        final_image = Image.fromarray(output_image)\n",
    "        final_image.save(output_path)\n",
    "        \n",
    "        # plt.savefig(output_path, bbox_inches='tight', pad_inches=0.1)\n",
    "        # plt.close(fig)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        # Save the mask as a grayscale PNG image\n",
    "        pred_mask_image = Image.fromarray(pred_mask_resized)\n",
    "        gt_mask_image = Image.fromarray(gt_mask)\n",
    "\n",
    "        mask_output_path = os.path.join(output_dir, f\"{image_file_name}_pred_mask.png\")\n",
    "        pred_mask_image.save(mask_output_path, \"PNG\")\n",
    "\n",
    "        gt_mask_output_path = os.path.join(output_dir, f\"{image_file_name}_gt_mask.png\")\n",
    "        gt_mask_image.save(gt_mask_output_path, \"PNG\")\n",
    "\n",
    "        print(f\"Saved predicted mask to {mask_output_path}\")\n",
    "\n",
    "\n",
    "        print(f\"Image: {image_file_name} | IoU: {iou:.4f} | AP50: {ap50:.4f} | AP75: {ap75:.4f} | mAP: {mAP:.4f}\")\n",
    "\n",
    "print(f\"IoU results saved to {iou_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Define directory and file paths\n",
    "changedetection_image_dir = 'SS_Rio_tile1024_stride0.v1i.coco-segmentation/test-new/segmentation_results_fp_fn'\n",
    "mask1_path = os.path.join(changedetection_image_dir, \"000000003537_png.rf.47308245be44358eabfd94bd7f4b857b.jpg_pred_mask.png\")\n",
    "mask2_path = os.path.join(changedetection_image_dir, \"3537-2020-12-16-resize.png_pred_mask.png\")\n",
    "\n",
    "# Check if both files exist\n",
    "if not (os.path.exists(mask1_path) and os.path.exists(mask2_path)):\n",
    "    raise FileNotFoundError(\"One or both mask files are missing!\")\n",
    "\n",
    "# Load masks\n",
    "mask1 = np.array(Image.open(mask1_path))\n",
    "mask2 = np.array(Image.open(mask2_path))\n",
    "\n",
    "# Ensure masks are binary\n",
    "mask1 = (mask1 > 0).astype(np.uint8) * 255\n",
    "mask2 = (mask2 > 0).astype(np.uint8) * 255\n",
    "\n",
    "# Subtract masks\n",
    "mask_diff = cv2.absdiff(mask1, mask2)\n",
    "\n",
    "# Save difference\n",
    "diff_output_path = os.path.join(changedetection_image_dir, \"mask_difference.png\")\n",
    "Image.fromarray(mask_diff).save(diff_output_path)\n",
    "\n",
    "print(f\"Saved mask difference to {diff_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGBA to RGB\n",
    "\n",
    "# Load the image\n",
    "# image = cv2.imread(r\"E:\\Workfolder\\favela\\image-processing\\inference\\SS_Rio_tile1024_stride0.v1i.coco-segmentation\\test-new\\3537-2020-12-16.png\")  # Reads the image in BGR format by default\n",
    "img_path = r'E:\\Workfolder\\favela\\image-processing\\inference\\SS_Rio_tile1024_stride0.v1i.coco-segmentation\\test-new\\3537-2020-12-16.png'\n",
    "\n",
    "# len(image.shape)\n",
    "\n",
    "img = Image.open(img_path)\n",
    "print(img.mode)\n",
    "# if img.mode == \"RGBA\":\n",
    "#     img = img.convert(\"RGB\")\n",
    "\n",
    "# # Save it back to ensure compatibility\n",
    "# img.save(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### instance segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test on single image, instance segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it on single image (instance segmentation), either on roboflow platform or using code\n",
    "\n",
    "# initialize the client\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"sRBH2PAnkPFSD53Ai589\"\n",
    ")\n",
    "\n",
    "custom_configuration = InferenceConfiguration(confidence_threshold=0.1) # 可以在这里设置theshold\n",
    "\n",
    "# infer on a local image\n",
    "image_path = 'data/000000000004_png.rf.d8640e1758f706d916fa47416a5b1735.jpg'\n",
    "\n",
    "with CLIENT.use_configuration(custom_configuration):\n",
    "    result = CLIENT.infer(image_path, model_id=\"is-favela-400-only-mask-wnngf/1\")\n",
    "\n",
    "# 加载原始图像\n",
    "image = Image.open(image_path).convert(\"RGBA\")  # 转换为支持透明度的 RGBA 模式\n",
    "overlay = Image.new(\"RGBA\", image.size, (255, 255, 255, 0))\n",
    "draw = ImageDraw.Draw(overlay)\n",
    "\n",
    "# 遍历预测结果，仅绘制多边形掩膜\n",
    "for prediction in result['predictions']:\n",
    "    \n",
    "    \n",
    "    print(prediction['confidence'])\n",
    "\n",
    "    # 获取类别标签\n",
    "    label = prediction['class']\n",
    "\n",
    "    # 绘制多边形掩膜\n",
    "    points = [(point['x'], point['y']) for point in prediction['points']]\n",
    "    draw.polygon(points, fill=(0, 0, 255, 30))  # 填充掩膜区域为蓝色\n",
    "    \n",
    "    # 在掩膜的第一个点处标注类别\n",
    "    draw.text(points[0], label, fill=\"white\")\n",
    "\n",
    "combined = Image.alpha_composite(image, overlay)\n",
    "\n",
    "# 显示结果图像并去除所有边框\n",
    "plt.imshow(combined)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "combined_output_path = \"demo/segmentation_result_combined.png\"\n",
    "combined.save(combined_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define merged_mask and compute_iou functions\n",
    "def merged_mask(masks):\n",
    "    if masks.ndim < 3 or masks.shape[2] == 0:\n",
    "        return masks if masks.ndim == 2 else masks[:, :, 0]\n",
    "    merged_mask = np.sum(masks, axis=2).astype(np.uint8)\n",
    "    return merged_mask\n",
    "\n",
    "def create_masks(polygons, shape):\n",
    "    \"\"\"\n",
    "    根据多边形列表创建掩码层。\n",
    "    \n",
    "    :param polygons: 多边形列表\n",
    "    :param shape: 掩码的形状 (height, width)\n",
    "    :return: 掩码层列表\n",
    "    \"\"\"\n",
    "    masks = []\n",
    "    for poly in polygons:\n",
    "        mask = np.zeros(shape, dtype=np.uint8)\n",
    "        pts = np.array(list(poly.exterior.coords), dtype=np.int32)\n",
    "        cv2.fillPoly(mask, [pts], 1)  # 用值 1 填充多边形\n",
    "        masks.append(mask)\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pt file \n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 初始化 YOLO 模型\n",
    "model = YOLO(\"yolo model/best.pt\")  # 替换为您自己的模型路径\n",
    "\n",
    "# 加载测试集路径\n",
    "image_dir = 'IS_Rio_tile1024_stride0.v1i.coco-segmentation/test-new'\n",
    "coco_json_path = os.path.join(image_dir, \"_annotations.coco.json\")\n",
    "\n",
    "with open(coco_json_path) as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "output_dir = os.path.join(image_dir, \"segmentation_results_fp_fn\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 初始化 IoU 结果 CSV\n",
    "iou_csv_path = os.path.join(output_dir, \"iou_results.csv\")\n",
    "with open(iou_csv_path, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"Image Name\", \"IoU\"])\n",
    "\n",
    "# 加载图像列表\n",
    "image_ids = [image['id'] for image in coco_data['images']]\n",
    "\n",
    "# 遍历测试图像\n",
    "for image_id in image_ids:  # 可用 random.sample(image_ids, min(4, len(image_ids))) 随机抽取 4 张\n",
    "    image_info = next(img for img in coco_data['images'] if img['id'] == image_id)\n",
    "    image_file_name = image_info['file_name']\n",
    "    img_path = os.path.join(image_dir, image_file_name)\n",
    "\n",
    "    # 读取 Ground Truth\n",
    "    gt_annotations = [anno for anno in coco_data['annotations'] if anno['image_id'] == image_id]\n",
    "    gt_polygons = []\n",
    "    for annotation in gt_annotations:\n",
    "        segmentation = annotation['segmentation'][0]\n",
    "        points = [(segmentation[i], segmentation[i + 1]) for i in range(0, len(segmentation), 2)]\n",
    "        gt_polygons.append(points)\n",
    "\n",
    "    # 推理\n",
    "    result = model(img_path)[0]  # 获取推理结果\n",
    "    predictions = result.masks.data.cpu().numpy() if result.masks is not None else []\n",
    "\n",
    "    # 初始化可视化\n",
    "    original_image = cv2.imread(img_path)\n",
    "    annotated_image = original_image.copy()\n",
    "    overlay = original_image.copy()\n",
    "\n",
    "    # 绘制 Ground Truth\n",
    "    gt_mask = np.zeros(original_image.shape[:2], dtype=np.uint8)\n",
    "    for polygon in gt_polygons:\n",
    "        cv2.fillPoly(gt_mask, [np.array(polygon, dtype=np.int32)], 1)\n",
    "        cv2.polylines(overlay, [np.array(polygon, dtype=np.int32)], isClosed=True, color=(255, 0, 0), thickness=2)\n",
    "\n",
    "    # 绘制 Predictions\n",
    "    pred_mask = np.zeros(original_image.shape[:2], dtype=np.uint8)\n",
    "    for pred in predictions:\n",
    "        coords = np.column_stack(np.where(pred > 0.5))  # 提取掩码的坐标\n",
    "        if coords.shape[0] > 0:\n",
    "            polygon = cv2.convexHull(coords)\n",
    "            cv2.fillPoly(pred_mask, [polygon], 1)\n",
    "            cv2.polylines(overlay, [polygon], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    # 计算 IoU\n",
    "    intersection = np.logical_and(gt_mask, pred_mask).sum()\n",
    "    union = np.logical_or(gt_mask, pred_mask).sum()\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "\n",
    "    # 保存 IoU 结果\n",
    "    # csv_writer.writerow([image_file_name, iou])\n",
    "\n",
    "    # 显示可视化\n",
    "    error_visualization = np.zeros_like(original_image, dtype=np.uint8)\n",
    "    error_visualization[gt_mask == 1] = [255, 0, 0]  # Red for FN\n",
    "    error_visualization[pred_mask == 1] = [0, 255, 0]  # Green for FP\n",
    "    error_visualization[np.logical_and(gt_mask == 1, pred_mask == 1)] = [255, 255, 0]  # Yellow for TP\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 10))\n",
    "    axs[0].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "    axs[0].axis('off')\n",
    "    axs[0].set_title('Original Image')\n",
    "\n",
    "    axs[1].imshow(overlay)\n",
    "    axs[1].axis('off')\n",
    "    axs[1].set_title('Overlay (Ground Truth + Predictions)')\n",
    "\n",
    "    axs[2].imshow(cv2.cvtColor(error_visualization, cv2.COLOR_BGR2RGB))\n",
    "    axs[2].axis('off')\n",
    "    axs[2].set_title(f'Error Visualization (IoU: {iou:.2f})')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print(f\"IoU results saved to {iou_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on folder, improved\n",
    "# to debug\n",
    "\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"uZgVV5Mu30Veqelqd61T\"\n",
    ")\n",
    "\n",
    "# confidence\n",
    "custom_configuration = InferenceConfiguration(confidence_threshold=0.3) # 可以在这里设置theshold\n",
    "CLIENT.use_configuration(custom_configuration)\n",
    "\n",
    "# model\n",
    "# CLIENT.select_model(model_id=\"is-favela-400-only-mask-wnngf/1\")\n",
    "# image_dir = 'IS-favela-400-only mask.v1i.coco/test' # input\n",
    "# CLIENT.select_model(model_id=\"is-favela-2048to1024-only-mask-drguu/1\")  #is-favela-2048to1024-maual/1 #这个模型不行\n",
    "\n",
    "CLIENT.select_model(model_id=\"is_rio_tile1024_stride0/1\")  \n",
    "image_dir = 'IS_Rio_tile1024_stride0.v1i.coco-segmentation/test-new' \n",
    "\n",
    "coco_json_path = os.path.join(image_dir, \"_annotations.coco.json\")\n",
    "\n",
    "with open(coco_json_path) as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "output_dir = os.path.join(image_dir, \"segmentation_results_fp_fn\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize CSV file for storing IoU results\n",
    "iou_csv_path = os.path.join(output_dir, \"iou_results.csv\")\n",
    "with open(iou_csv_path, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"Image Name\", \"IoU\"]) \n",
    "\n",
    "    image_ids = [image['id'] for image in coco_data['images']]\n",
    "\n",
    "    for image_id in image_ids:  # [:5]， Process first 5 images\n",
    "        image_info = next(img for img in coco_data['images'] if img['id'] == image_id)\n",
    "        image_file_name = image_info['file_name']\n",
    "        img_path = os.path.join(image_dir, image_file_name)\n",
    "\n",
    "        gt_annotations = [anno for anno in coco_data['annotations'] if anno['image_id'] == image_id]\n",
    "\n",
    "        # Read image and initialize overlay\n",
    "        im = cv2.imread(img_path)\n",
    "        overlay = Image.new(\"RGBA\", (im.shape[1], im.shape[0]), (255, 255, 255, 0))\n",
    "        draw = ImageDraw.Draw(overlay)\n",
    "\n",
    "        gt_polygons = []\n",
    "        for annotation in gt_annotations:\n",
    "            segmentation = annotation['segmentation'][0]\n",
    "            points = [(segmentation[i], segmentation[i + 1]) for i in range(0, len(segmentation), 2)]\n",
    "            gt_polygons.append(Polygon(points))\n",
    "            draw.polygon(points, fill=(255, 255, 255, 100))  # Ground Truth overlay\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGBA\")\n",
    "        combined_gt = Image.alpha_composite(image, overlay)\n",
    "\n",
    "        \n",
    "        # result = CLIENT.infer(img_path)\n",
    "        result = CLIENT.infer(img_path)\n",
    "\n",
    "        original_image = Image.open(img_path).convert(\"RGBA\")\n",
    "\n",
    "        overlay_pred = Image.new(\"RGBA\", (im.shape[1], im.shape[0]), (255, 255, 255, 0))\n",
    "        draw_pred = ImageDraw.Draw(overlay_pred)\n",
    "\n",
    "        pred_polygons = []\n",
    "        for prediction in result['predictions']:\n",
    "            points = [(point['x'], point['y']) for point in prediction['points']]\n",
    "            pred_polygons.append(Polygon(points))\n",
    "            draw_pred.polygon(points, fill=(0, 0, 255, 30))  # Prediction overlay\n",
    "\n",
    "        pred_image = Image.open(img_path).convert(\"RGBA\")\n",
    "        combined_pred = Image.alpha_composite(pred_image, overlay_pred)\n",
    "\n",
    "\n",
    "        # IoU computation, TBD: instance segmentation用IOU是合适的吗？可以之后跟semantic segmentation进行比较；GPT也不是很靠谱一开始生成的是平均IOU，实际应该用加权的\n",
    "        gt_masks = []\n",
    "        pred_masks = []\n",
    "\n",
    "        # 为 ground truth, predictions 创建掩码层\n",
    "        gt_masks = create_masks(gt_polygons, (im.shape[0], im.shape[1]))\n",
    "        pred_masks = create_masks(pred_polygons, (im.shape[0], im.shape[1]))\n",
    "\n",
    "        if gt_masks:  # 检查 gt_masks 是否为空\n",
    "            merged_gt_mask = merged_mask(np.stack(gt_masks, axis=-1))\n",
    "        else:\n",
    "            merged_gt_mask = np.zeros((im.shape[0], im.shape[1]), dtype=np.uint8)\n",
    "\n",
    "        # Prediction merged_mask\n",
    "        if pred_masks:  # 检查 pred_masks 是否为空\n",
    "            merged_pred_mask = merged_mask(np.stack(pred_masks, axis=-1))\n",
    "        else:\n",
    "            merged_pred_mask = np.zeros((im.shape[0], im.shape[1]), dtype=np.uint8)\n",
    "\n",
    "        # 计算 IoU：使用掩码的像素级别重叠计算\n",
    "        intersection = np.logical_and(merged_gt_mask, merged_pred_mask).sum()  # 重叠区域\n",
    "        union = np.logical_or(merged_gt_mask, merged_pred_mask).sum()          # 联合区域\n",
    "\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "\n",
    "\n",
    "        # Calculate error mask\n",
    "        # error_mask = cv2.bitwise_and(merged_gt_mask, cv2.bitwise_not(merged_pred_mask))\n",
    "        # False Negative (FN): Ground Truth is 1, Prediction is 0\n",
    "        fn_mask = np.logical_and(merged_gt_mask == 1, merged_pred_mask == 0).astype(np.uint8) * 255\n",
    "        # False Positive (FP): Prediction is 1, Ground Truth is 0\n",
    "        fp_mask = np.logical_and(merged_pred_mask == 1, merged_gt_mask == 0).astype(np.uint8) * 255\n",
    "\n",
    "\n",
    "        error_image = Image.fromarray(np.where(error_mask[..., None] == 255, [255, 255, 255, 255], [0, 0, 0, 255]).astype(np.uint8)) # 黑底白块\n",
    "        # error_image = Image.fromarray(np.where(error_mask[..., None] == 255, [0, 0, 0, 255], [255, 255, 255, 255]).astype(np.uint8)) # 白底黑块\n",
    "\n",
    "        # Error overlay (FN in red, FP in blue)\n",
    "        # overlay_error = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 255))\n",
    "        # fn_pil = Image.fromarray(fn_mask).convert(\"L\")\n",
    "        # fp_pil = Image.fromarray(fp_mask).convert(\"L\")\n",
    "        # error_draw = ImageDraw.Draw(overlay_error)\n",
    "        # error_draw.bitmap((0, 0), fn_pil, fill=(255, 255, 255, 255))  # Red for False Negative, (255, 0, 0, 100)\n",
    "        # error_draw.bitmap((0, 0), fp_pil, fill=(128, 128, 128, 255))  # Blue for False Positive,(0, 0, 255, 100)\n",
    "        # combined_error = overlay_error\n",
    "\n",
    "        # Combined Error Map with Transparency (FN in Red, FP in Blue)\n",
    "        error_visualization = np.zeros((merged_gt_mask.shape[0], merged_gt_mask.shape[1], 3), dtype=np.uint8)  # RGBA\n",
    "        error_visualization[fn_mask == 255] = [255, 255, 255]  \n",
    "        error_visualization[fp_mask == 255] = [128, 128, 128]  \n",
    "        combined_error = Image.fromarray(error_visualization, mode=\"RGB\")\n",
    "\n",
    "        # Write IoU to CSV file\n",
    "        csv_writer.writerow([image_file_name, iou])\n",
    "\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        axs[0].imshow(original_image)\n",
    "        axs[0].axis('off')\n",
    "        axs[0].set_title('Original Image')\n",
    "\n",
    "        axs[1].imshow(combined_gt)\n",
    "        axs[1].axis('off')\n",
    "        axs[1].set_title('Ground Truth')\n",
    "        \n",
    "        axs[2].imshow(combined_pred)\n",
    "        axs[2].axis('off')\n",
    "        axs[2].set_title('Prediction')\n",
    "\n",
    "        axs[3].imshow(np.array(combined_error))  # Error visualization (FN & FP)\n",
    "        axs[3].axis('off')\n",
    "        axs[3].set_title(f'Error (IoU: {iou:.4f})')\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"{image_file_name}_result.png\")\n",
    "\n",
    "        # Add labels to each image\n",
    "        original_with_label = add_labels(original_image, \"Original Image\")\n",
    "        gt_with_label = add_labels(combined_gt, \"Ground Truth\")\n",
    "        pred_with_label = add_labels(combined_pred, \"Prediction\")\n",
    "        error_with_label = add_labels(combined_error, \"Error Map\", iou=iou)\n",
    "\n",
    "        output_image = np.hstack([\n",
    "            np.array(original_with_label),\n",
    "            np.array(gt_with_label),\n",
    "            np.array(pred_with_label),\n",
    "            np.array(error_with_label)\n",
    "        ])\n",
    "        final_image = Image.fromarray(output_image)\n",
    "        final_image.save(output_path)\n",
    "        \n",
    "        # plt.savefig(output_path, bbox_inches='tight', pad_inches=0.1)\n",
    "        plt.close(fig)\n",
    "        # plt.show()\n",
    "\n",
    "        print(f\"Image {image_file_name} accuracy (IoU): {iou:.4f}\")\n",
    "print(f\"IoU results saved to {iou_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test on folder\n",
    "\n",
    "# CLIENT = InferenceHTTPClient(\n",
    "#     api_url=\"https://detect.roboflow.com\",\n",
    "#     api_key=\"uZgVV5Mu30Veqelqd61T\"\n",
    "# )\n",
    "\n",
    "# # confidence\n",
    "# custom_configuration = InferenceConfiguration(confidence_threshold=0.1) # 可以在这里设置theshold\n",
    "# CLIENT.use_configuration(custom_configuration)\n",
    "\n",
    "# # model\n",
    "# # CLIENT.select_model(model_id=\"is-favela-400-only-mask-wnngf/1\")\n",
    "# # image_dir = 'IS-favela-400-only mask.v1i.coco/test' # input\n",
    "# # CLIENT.select_model(model_id=\"is-favela-2048to1024-only-mask-drguu/1\")  #is-favela-2048to1024-maual/1 #这个模型不行\n",
    "\n",
    "# CLIENT.select_model(model_id=\"is_rio_tile1024_stride0/1\")  \n",
    "# image_dir = 'IS_Rio_tile1024_stride0.v1i.coco-segmentation/test' \n",
    "\n",
    "# coco_json_path = os.path.join(image_dir, \"_annotations.coco.json\")\n",
    "\n",
    "# with open(coco_json_path) as f:\n",
    "#     coco_data = json.load(f)\n",
    "\n",
    "# output_dir = os.path.join(image_dir, \"segmentation_results\")\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Initialize CSV file for storing IoU results\n",
    "# iou_csv_path = os.path.join(output_dir, \"iou_results.csv\")\n",
    "# with open(iou_csv_path, mode='w', newline='') as csv_file:\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "#     csv_writer.writerow([\"Image Name\", \"IoU\"]) \n",
    "\n",
    "#     image_ids = [image['id'] for image in coco_data['images']]\n",
    "\n",
    "#     for image_id in image_ids:  # [:5]， Process first 5 images\n",
    "#         image_info = next(img for img in coco_data['images'] if img['id'] == image_id)\n",
    "#         image_file_name = image_info['file_name']\n",
    "#         img_path = os.path.join(image_dir, image_file_name)\n",
    "\n",
    "#         gt_annotations = [anno for anno in coco_data['annotations'] if anno['image_id'] == image_id]\n",
    "\n",
    "#         # Read image and initialize overlay\n",
    "#         im = cv2.imread(img_path)\n",
    "#         overlay = Image.new(\"RGBA\", (im.shape[1], im.shape[0]), (255, 255, 255, 0))\n",
    "#         draw = ImageDraw.Draw(overlay)\n",
    "\n",
    "#         gt_polygons = []\n",
    "#         for annotation in gt_annotations:\n",
    "#             segmentation = annotation['segmentation'][0]\n",
    "#             points = [(segmentation[i], segmentation[i + 1]) for i in range(0, len(segmentation), 2)]\n",
    "#             gt_polygons.append(Polygon(points))\n",
    "#             draw.polygon(points, fill=(255, 255, 255, 100))  # Ground Truth overlay\n",
    "\n",
    "#         image = Image.open(img_path).convert(\"RGBA\")\n",
    "#         gt_combined = Image.alpha_composite(image, overlay)\n",
    "\n",
    "        \n",
    "#         result = CLIENT.infer(img_path)\n",
    "\n",
    "#         overlay_pred = Image.new(\"RGBA\", (im.shape[1], im.shape[0]), (255, 255, 255, 0))\n",
    "#         draw_pred = ImageDraw.Draw(overlay_pred)\n",
    "\n",
    "#         pred_polygons = []\n",
    "#         for prediction in result['predictions']:\n",
    "#             points = [(point['x'], point['y']) for point in prediction['points']]\n",
    "#             pred_polygons.append(Polygon(points))\n",
    "#             draw_pred.polygon(points, fill=(0, 0, 255, 30))  # Prediction overlay\n",
    "\n",
    "#         pred_image = Image.open(img_path).convert(\"RGBA\")\n",
    "#         pred_combined = Image.alpha_composite(pred_image, overlay_pred)\n",
    "\n",
    "#         # Create masks\n",
    "#         gt_mask = np.zeros((im.shape[0], im.shape[1]), dtype=np.uint8)\n",
    "#         pred_mask = np.zeros((im.shape[0], im.shape[1]), dtype=np.uint8)\n",
    "\n",
    "#         for poly in gt_polygons:\n",
    "#             pts = np.array(list(poly.exterior.coords), dtype=np.int32)\n",
    "#             cv2.fillPoly(gt_mask, [pts], 255)\n",
    "\n",
    "#         for poly in pred_polygons:\n",
    "#             pts = np.array(list(poly.exterior.coords), dtype=np.int32)\n",
    "#             cv2.fillPoly(pred_mask, [pts], 255)\n",
    "\n",
    "#         # Calculate error mask\n",
    "#         error_mask = cv2.bitwise_and(gt_mask, cv2.bitwise_not(pred_mask))\n",
    "\n",
    "#         error_image = Image.fromarray(np.where(error_mask[..., None] == 255, [255, 255, 255, 255], [0, 0, 0, 255]).astype(np.uint8)) # 黑底白块\n",
    "#         # error_image = Image.fromarray(np.where(error_mask[..., None] == 255, [0, 0, 0, 255], [255, 255, 255, 255]).astype(np.uint8)) # 白底黑块\n",
    "\n",
    "\n",
    "#         # IoU computation, TBD: instance segmentation用IOU是合适的吗？可以之后跟semantic segmentation进行比较；GPT也不是很靠谱一开始生成的是平均IOU，实际应该用加权的\n",
    "#         total_intersection = 0\n",
    "#         total_union = 0\n",
    "\n",
    "#         for gt_polygon in gt_polygons:\n",
    "#             if not gt_polygon.is_valid:  # 跳过无效的多边形\n",
    "#                 print(f\"Skipping invalid ground truth polygon in {image_file_name}\")\n",
    "#                 continue\n",
    "#             for pred_polygon in pred_polygons:\n",
    "#                 if not pred_polygon.is_valid:  # 跳过无效的多边形\n",
    "#                     print(f\"Skipping invalid prediction polygon in {image_file_name}\")\n",
    "#                     continue\n",
    "#                 if gt_polygon.intersects(pred_polygon):\n",
    "#                     try:\n",
    "#                         intersection_area = gt_polygon.intersection(pred_polygon).area\n",
    "#                         union_area = gt_polygon.union(pred_polygon).area\n",
    "#                         total_intersection += intersection_area\n",
    "#                         total_union += union_area\n",
    "#                     except TopologicalError:\n",
    "#                         print(f\"Skipping union calculation due to TopologyException for {image_file_name}\")\n",
    "\n",
    "\n",
    "#         weighted_iou = total_intersection / total_union if total_union > 0 else 0\n",
    "#         # Write IoU to CSV file\n",
    "#         csv_writer.writerow([image_file_name, weighted_iou])\n",
    "\n",
    "#         fig, axs = plt.subplots(1, 3, figsize=(16, 8))\n",
    "#         axs[0].imshow(gt_combined)\n",
    "#         axs[0].axis('off')\n",
    "#         axs[0].set_title('Ground Truth')\n",
    "        \n",
    "#         axs[1].imshow(pred_combined)\n",
    "#         axs[1].axis('off')\n",
    "#         axs[1].set_title('Prediction')\n",
    "\n",
    "#         axs[2].imshow(error_image)\n",
    "#         axs[2].axis('off')\n",
    "#         axs[2].set_title(f'Error (IoU: {weighted_iou:.4f})')\n",
    "\n",
    "#         plt.figtext(0.5, 0.2, image_file_name, ha='center', fontsize=12)\n",
    "\n",
    "#         output_path = os.path.join(output_dir, f\"{image_file_name}_result.png\")\n",
    "#         plt.savefig(output_path, bbox_inches='tight', pad_inches=0.1)\n",
    "        \n",
    "#         # plt.close(fig) \n",
    "#         plt.show()\n",
    "\n",
    "#         print(f\"Image {image_file_name} accuracy (IoU): {weighted_iou:.4f}\")\n",
    "# print(f\"IoU results saved to {iou_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"sRBH2PAnkPFSD53Ai589\")\n",
    "project = rf.workspace(\"my-first-workspace-list1\").project(\"is-favela-2048to1024-only-mask-drguu\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"coco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
